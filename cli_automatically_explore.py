#!/usr/bin/env python
import argparse
import pandas as pd
from pandas_profiling import ProfileReport


def main() -> None:

    parser = argparse.ArgumentParser(description="Remove processed hashes from csv")
    parser.add_argument(
        "input_hdf_path",
        metavar="INPUT_HDF_PATH", 
        type=str, 
        help="path to hdf file"
    )
    parser.add_argument(
        "output_html_path",
        metavar="OUTPUT_HTML_PATH", 
        type=str, 
        help="path where to store html report"
    )
    parser.add_argument(
        "--sample_size",
        type=int,
        default=10000,
        help="Size of sample to take for analysis. By default 10 000."
    )
    parser.add_argument(
        "--minimal_mode",
        default=False,
        action="store_true",
        help="Use minimal mode. When this is enabled then --sample_size is ignored and whole dataset is used."
    )
    parser.add_argument(
        "--features_hdf_key",
        default="X_train",
        type=str,
        help="Key under which features are stored in input hdf file. By default X_train."
    )
    parser.add_argument(
        "--targets_hdf_key",
        default="y_train",
        type=str,
        help="Key under which targets are stored in input hdf file. By default y_train."
    )
    args = parser.parse_args()
    X = pd.read_hdf(args.features_csv_path, key=args.features_hdf_key)
    y = pd.read_hdf(args.target_csv_path, key=args.targets_hdf_key).squeeze("columns")  
    sample_size = args.sample_size if args.sample_size <= X.shape[0] else X.shape[0]

    df = X
    df[y.name] = y
    
    sample = df.sample(sample_size) if not args.minimal_mode else df
    profile = ProfileReport(
        sample, 
        title=f"Automatic exploratory data analysis (warning: uses only {sample_size} samples)", 
        html={"style": {"full_width": True}}, 
        sort=None,
        explorative=True,
        minimal=args.minimal_mode
    )
    profile.to_file(args.output_html_path)


if __name__ == "__main__":
    main()
