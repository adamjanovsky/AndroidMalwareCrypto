# Note: this is currently supposed to be only supported for Tree Based models, specifically Random Forest.

columns_to_ignore: # must correspond to columns in trainign config
  - "metadata_source"
  - "metadata_dex_year"
  - "metadata_n_lines"
  - "metadata_n_classes"

# parameters related to input
model_path: "data/malware_detection_rf.joblib" # pickle or joblib
hdf_path: "data/malware_detection_full.h5" # path to hdf file from which 'X_test' and 'y_test' keys are used
sample_size: -1 # sample size to draw, in case of non-positive number or number bigger than values use it all
indices: Null # optional list of indices to use

# parameters that change calculations
feature_perturbation: "tree_path_dependent" # "interventional" or "tree_path_dependent" - please refer to TreeExplainer documentation
model_output: "raw" # what output of the model should be explained, "raw"/"probability"/"log_loss" - see TreeExplainer docs
approximate: False # when True the method of calculating shap values is faster but might be slower. See TreeExplainer documentation.
calculate_shap_values: True
calculate_interaction_values: True

save_values: True # whether to save values - this might be useless when whole dataset is used
save_targets: True # wheter to save targets - this might be useless when whole dataset is used
save_hashes: True # whether to save hashes of used samples

output_path: "data/shap.h5"
# save the output into a single h5 file in this format:
# keys: 
#   - shap_values             - dataframe of shap values
#   - shap_interaction_values - dataframe of shap interaction values
#   - values                  - dataframe of values used
#   - shap_expected_values    - dataframe (series because only one column) of shap expected values
#   - targets                 - dataframe (series because only one column) of targets, not saved if target_path is Null
#   - hashes                  - dataframe (series because only one column) of hashes
output_explainer_path: Null # optional path to save explainer to using pickle