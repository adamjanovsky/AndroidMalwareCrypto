{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dataclasses import dataclass, field, InitVar\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import re\n",
    "import copy\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "from typing import Any\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option(\"display.max_colwidth\", 102)\n",
    "pd.set_option(\"display.max_rows\", 102)\n",
    "\n",
    "sns.set_style(\"whitegrid\", {\n",
    "    \"ytick.major.size\": 0.1,\n",
    "    \"ytick.minor.size\": 0.05,\n",
    "    'grid.linestyle': '--'\n",
    " })\n",
    "\n",
    "def get_category_triggers(api_definition, category):\n",
    "    obfuscated_trigger = None\n",
    "    complex_cat = False\n",
    "    \n",
    "    if len(api_definition[category].keys()) > 2:\n",
    "        triggers = {}\n",
    "        complex_cat = True\n",
    "    else:\n",
    "        triggers = []\n",
    "    \n",
    "    for key, subcat_triggers in api_definition[category].items():\n",
    "        if key == 'obfuscated':\n",
    "            obfuscated_trigger = subcat_triggers\n",
    "            if complex_cat == True:\n",
    "                triggers[key] = subcat_triggers\n",
    "        else:\n",
    "            if complex_cat == True:\n",
    "                triggers[key] = subcat_triggers\n",
    "            else:\n",
    "                triggers.extend(subcat_triggers)\n",
    "                \n",
    "    return obfuscated_trigger, triggers, complex_cat\n",
    "\n",
    "def get_triggers(inp):\n",
    "    if isinstance(inp, dict):\n",
    "        triggers = []\n",
    "        for k in inp.keys():\n",
    "            if k != 'obfuscated':\n",
    "                triggers.extend(inp[k])\n",
    "        return inp['obfuscated'], triggers\n",
    "    if isinstance(inp, list):\n",
    "        return None, inp\n",
    "    \n",
    "def strip_triggers(triggers):\n",
    "    dct = {}\n",
    "    for t in triggers:\n",
    "        if '\"' in t:\n",
    "            dct[t] = t.split('\"')[1]\n",
    "        else:\n",
    "            dct[t] = 'obfuscated'\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about third-party packages\n",
      "210310 out of 251996 (83.46%) apks contain at least one third party package\n",
      "On average, each apk contains: 7.921478912363688 third-party packages.\n",
      "--------------------------------------------------------------------------------\n",
      "General statistics about dataset\n",
      "Number of analyzed samples: 251,996\n",
      "How many of analyzed samples use some crypto...\n",
      "|   year |   all_samples |   containing_crypto |   empty_samples |   percentage_containing_crypto |\n",
      "|-------:|--------------:|--------------------:|----------------:|-------------------------------:|\n",
      "|   2012 |         39767 |               21649 |           18118 |                        54.4396 |\n",
      "|   2013 |         39674 |               26819 |           12855 |                        67.5984 |\n",
      "|   2014 |         39794 |               22998 |           16796 |                        57.7926 |\n",
      "|   2015 |         39745 |               19885 |           19860 |                        50.0315 |\n",
      "|   2016 |         39325 |               16943 |           22382 |                        43.0846 |\n",
      "|   2017 |         34386 |                9251 |           25135 |                        26.9034 |\n",
      "|   2018 |         19305 |                5186 |           14119 |                        26.8635 |\n",
      "--------------------------------------------------------------------------------\n",
      "Usage of third party cryptographic libraries\n",
      "Java libraries:\n",
      "year  lib_name                              \n",
      "2012  Lorg/keyczar                              39\n",
      "      Lnet/sqlcipher                             8\n",
      "2013  Lorg/keyczar                              42\n",
      "      Lnet/sqlcipher                             1\n",
      "2014  Lorg/keyczar                              33\n",
      "      Lnet/sqlcipher                            16\n",
      "2015  Lnet/sqlcipher                            27\n",
      "      Lorg/keyczar                               5\n",
      "2016  Lnet/sqlcipher                            15\n",
      "      Lorg/keyczar                               5\n",
      "      Linfo/guardianproject/netcipher/client     1\n",
      "      Linfo/guardianproject/netcipher/proxy      1\n",
      "2017  Lnet/sqlcipher                             3\n",
      "2018  Lnet/sqlcipher                             2\n",
      "      Lgnu/crypto/assembly                       1\n",
      "      Lgnu/crypto/cipher                         1\n",
      "      Lgnu/crypto/jce/cipher                     1\n",
      "      Lgnu/crypto/key/rsa                        1\n",
      "      Lgnu/crypto/keyring                        1\n",
      "      Lgnu/crypto/sasl/crammd5                   1\n",
      "      Lgnu/crypto/sasl/plain                     1\n",
      "      Lgnu/crypto/sig/dss                        1\n",
      "Name: lib_name, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Prevalence of java libraries per year:\n",
      "year\n",
      "2012    47\n",
      "2013    43\n",
      "2014    49\n",
      "2015    32\n",
      "2016    21\n",
      "2017     3\n",
      "2018     3\n",
      "Name: sha256, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "Overall popularity of java libraries:\n",
      "Lorg/keyczar                              124\n",
      "Lnet/sqlcipher                             72\n",
      "Lgnu/crypto/key/rsa                         1\n",
      "Linfo/guardianproject/netcipher/client      1\n",
      "Lgnu/crypto/sig/dss                         1\n",
      "Lgnu/crypto/keyring                         1\n",
      "Linfo/guardianproject/netcipher/proxy       1\n",
      "Lgnu/crypto/jce/cipher                      1\n",
      "Lgnu/crypto/assembly                        1\n",
      "Lgnu/crypto/cipher                          1\n",
      "Lgnu/crypto/sasl/plain                      1\n",
      "Lgnu/crypto/sasl/crammd5                    1\n",
      "Name: lib_name, dtype: int64\n",
      "Native libraries:\n",
      "No native cryptographic libraries were found\n",
      "--------------------------------------------------------------------------------\n",
      "Number of crypto API imports per sample:\n",
      "|       |   crypto_imports_sum |\n",
      "|:------|---------------------:|\n",
      "| count |          122731      |\n",
      "| mean  |              13.2968 |\n",
      "| std   |              26.4501 |\n",
      "| min   |               0      |\n",
      "| 25%   |               2      |\n",
      "| 50%   |               7      |\n",
      "| 75%   |              14      |\n",
      "| max   |            2462      |\n",
      "Out of 86 analyzed classes, the following number is actually imported:\n",
      "year\n",
      "2012    57\n",
      "2013    60\n",
      "2014    74\n",
      "2015    75\n",
      "2016    70\n",
      "2017    63\n",
      "2018    73\n",
      "Name: api_class, dtype: int64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load evaluator object and evaluate basic stuff\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('/Users/adam/phd/projects/CryptoMalware/repos/AndroidMalwareCrypto'))\n",
    "from androidcrypto.evaluate.evaluator import Evaluator\n",
    "evaluator = Evaluator('/Users/adam/phd/projects/CryptoMalware/experiments/rigo', '/Users/adam/phd/projects/CryptoMalware/experiments/report', '/Users/adam/phd/projects/CryptoMalware/experiments/api_definition.yml')\n",
    "evaluator.evaluate()\n",
    "#df_cipher = evaluator.plot_ciphers(evaluator.df_records, '', deepcopy(evaluator.exp_config['evaluate']['categories']['Cipher']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_triggers(obj):\n",
    "    triggers = []\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        if len(obj.keys()) == 2:\n",
    "            for key in obj.keys():\n",
    "                if key != 'obfuscated':\n",
    "                    triggers.extend(get_all_triggers(obj[key]))\n",
    "                else:\n",
    "                    triggers.append(obj[key])\n",
    "        elif len(obj.keys()) > 2:\n",
    "            for key in obj.keys():\n",
    "                triggers.extend(get_all_triggers(obj[key]))\n",
    "    elif isinstance(obj, list):\n",
    "        triggers = obj\n",
    "    \n",
    "    return triggers\n",
    "\n",
    "@dataclass\n",
    "class Comparison:\n",
    "    name: str\n",
    "    categories: Any\n",
    "    path: str\n",
    "    obfuscated_trigger: str\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'name: {self.name}, path: {self.path}, obf: {self.obfuscated_trigger}'       \n",
    "\n",
    "def get_all_comps(obj, path, name, obfuscated_trigger):\n",
    "    comps = []\n",
    "    \n",
    "    if isinstance(obj, list):\n",
    "        cats = {x.split('\"')[1]: [x] for x in obj}\n",
    "        comps.append(Comparison(name, cats, path, obfuscated_trigger))\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        if len(obj.keys()) > 2:\n",
    "            comps.append(Comparison(name, {key: get_all_triggers(val) for key, val in obj.items()}, os.path.join(path), obfuscated_trigger))\n",
    "            \n",
    "            for key, val in obj.items():\n",
    "                comps.extend(get_all_comps(val, os.path.join(path, key), key, None))\n",
    "            \n",
    "        if len(obj.keys()) == 2:\n",
    "            comps.extend(get_all_comps(obj['values'], path, name, obj['obfuscated']))\n",
    "    \n",
    "    return comps\n",
    "\n",
    "def get_df_temp(category_name, category_triggers, df_eval, sum_temp_n_call_sites):\n",
    "    df = df_eval.loc[df_eval.trigger.isin(category_triggers)].groupby('year')\n",
    "    \n",
    "    temp_n_call_sites = df.trigger.count()\n",
    "    temp_n_call_sites.name = 'n_call_sites'\n",
    "\n",
    "    temp_norm_n_call_sites = temp_n_call_sites / temp_n_call_sites.index.map(evaluator.norm_factor)\n",
    "    temp_norm_n_call_sites = temp_norm_n_call_sites.map(math.ceil)\n",
    "    temp_norm_n_call_sites.name = 'norm_n_call_sites'\n",
    "\n",
    "    temp_n_apks = df.sha256.nunique()\n",
    "    temp_n_apks.name = 'n_apks'\n",
    "\n",
    "    df_to_return = pd.concat([temp_n_call_sites, temp_norm_n_call_sites, temp_n_apks], axis=1)\n",
    "    df_to_return['category'] = category_name\n",
    "    df_to_return = df_to_return.set_index('category', append=True)\n",
    "    df_to_return['norm_n_apks'] = df_to_return.n_apks / df_to_return.index.map(map_norm_factor_multiindex)\n",
    "    df_to_return.norm_n_apks = df_to_return.norm_n_apks.astype('int64')\n",
    "\n",
    "    df_to_return['norm_n_apks_ratio'] = 100 * (df_to_return.norm_n_apks / 10000)\n",
    "    df_to_return['n_call_sites_ratio'] = 100 * (df_to_return.n_call_sites / sum_temp_n_call_sites)\n",
    "    \n",
    "    return df_to_return\n",
    "\n",
    "def get_df_summary(df_eval, df_temp, dataset_size, all_triggers):\n",
    "    df = df_temp.drop(columns=['norm_n_call_sites', 'norm_n_apks', 'norm_n_apks_ratio', 'n_call_sites_ratio']).sum(level='category')\n",
    "    sum_n_call_sites = df.n_call_sites.sum()\n",
    "    sum_n_apks = df_eval.loc[df_eval.trigger.isin(all_triggers)].sha256.nunique()\n",
    "\n",
    "    df['call_sites_ratio'] = 100 * df.n_call_sites / sum_n_call_sites\n",
    "    df['n_apks_ratio'] = 100 * df.n_apks / dataset_size\n",
    "\n",
    "    sum_row = pd.Series([sum_n_call_sites, sum_n_apks, 1, 100 * sum_n_apks / dataset_size], index=['n_call_sites', 'n_apks', 'call_sites_ratio', 'n_apks_ratio'], name='Total')\n",
    "    df = df.append(sum_row)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evaluate_comparison(comparison):\n",
    "    if not os.path.exists(comparison.path):\n",
    "        os.makedirs(comparison.path)\n",
    "    \n",
    "    if comparison.obfuscated_trigger is not None:\n",
    "        comparison.categories['obfuscated'] = [comparison.obfuscated_trigger]\n",
    "    \n",
    "    all_triggers = get_all_triggers(comparison.categories)\n",
    "    sum_temp_n_call_sites  = evaluator.df_records.loc[evaluator.df_records.trigger.isin(all_triggers)].groupby('year').trigger.count()\n",
    "    temps = []\n",
    "\n",
    "    for cat_name, cat_triggers in comparison.categories.items():\n",
    "        temps.append(get_df_temp(cat_name, cat_triggers, evaluator.df_records, sum_temp_n_call_sites))\n",
    "\n",
    "    df_temp = pd.concat(temps)\n",
    "    df_temp.to_html(os.path.join(comparison.path, 'temporal_evolution.html'))\n",
    "    \n",
    "    if not df_temp.empty:\n",
    "        plot_temporal_evolution(df_temp, os.path.join(comparison.path, 'temporal_evolution.png'), comparison.name)\n",
    "        plot_boxplot(df_temp, os.path.join(comparison.path, 'boxplot.png'), comparison.name)\n",
    "    \n",
    "    df_sum = get_df_summary(evaluator.df_records, df_temp, evaluator.dset_size, all_triggers)\n",
    "    df_sum.to_html(os.path.join(comparison.path, 'summary.html'))\n",
    "\n",
    "def plot_temporal_evolution(df_temp, path, title, drop_obfuscated=True):\n",
    "    \n",
    "    df = df_temp.reset_index()\n",
    "    \n",
    "    if drop_obfuscated is True:\n",
    "        df = df.loc[df.category != 'obfuscated']\n",
    "    \n",
    "    df = df.sort_values(by='norm_n_apks_ratio', ascending=False)\n",
    "    \n",
    "    ax = sns.lineplot(x='year', y='norm_n_apks_ratio', hue='category', data=df, marker='o')\n",
    "    #ax.yaxis.set_major_locator(mtick.MultipleLocator(5)) # density of grid lines, 5% now\n",
    "    ax.xaxis.set_major_locator(mtick.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "    ax.set(xlabel='Year', ylabel='% of all samples',\n",
    "           title=title)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    ax.figure.savefig(path, dpi=300, format='png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "def plot_boxplot(df_temp, path, title, drop_obfuscated=True):\n",
    "    df = df_temp.reset_index()\n",
    "    \n",
    "    if drop_obfuscated is True:\n",
    "        df = df.loc[df.category != 'obfuscated']\n",
    "    \n",
    "    df = df.sort_values(by='norm_n_apks_ratio', ascending=False)\n",
    "    \n",
    "    df = df.sort_values(by=['norm_n_apks'], ascending=False)\n",
    "    ax = sns.boxplot(x='category', y='norm_n_apks', data=df)\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set(xlabel=f'category', ylabel='Number of APKs per 10k APKs', title=f'{title} frequency')\n",
    "    ax.figure.savefig(path, dpi=300, format='png',\n",
    "                      bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/adam/phd/projects/CryptoMalware/experiments/api_definition.yml', 'r') as handle:\n",
    "    stream = yaml.load(handle, Loader=yaml.FullLoader)\n",
    "\n",
    "comparisons = get_all_comps(stream, '/Users/adam/phd/projects/CryptoMalware/experiments/eval', 'all', None)\n",
    "for cmp in comparisons:\n",
    "    evaluate_comparison(cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual comparison with ASIACCS 2018 benign dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_n_samples = 115683\n",
    "benign_n_call_sites = 251021\n",
    "downscale_factor = evaluator.dataset_sizes[2016] / benign_n_samples\n",
    "third_party_lib_factor = 9.3 / 100\n",
    "print(f'Benign call sites downscaled from {benign_n_call_sites}: {downscale_factor * third_party_lib_factor * benign_n_call_sites}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_calls(year, triggers):\n",
    "    return evaluator.df_records.loc[(evaluator.df_records.year == year) & (evaluator.df_records.trigger.isin(triggers))].shape[0]\n",
    "\n",
    "def analyze_cipher_distribution(year, categories):\n",
    "    obf_triggers = ['Cipher.getInstance(']\n",
    "    obf_calls = get_n_calls(year, obf_triggers)\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    \n",
    "    all_triggers = flatten([evaluator.api_definition['encryption'][cat] for cat in categories]) + obf_triggers\n",
    "    all_calls = get_n_calls(year, all_triggers)\n",
    "    print(f'all calls: {all_calls} ({(100 * all_calls / all_calls):.2f}%)')\n",
    "    print(f'obfuscated calls: {obf_calls} ({(100 * obf_calls / all_calls):.2f}%)')\n",
    "    \n",
    "    for cat in categories:\n",
    "        cat_triggers = evaluator.api_definition['encryption'][cat]\n",
    "        cat_calls = get_n_calls(year, cat_triggers)\n",
    "        print(f'{cat} calls: {cat_calls} ({(100 * cat_calls / all_calls):.2f}%)')\n",
    "\n",
    "# todo: place RC4 below instead of ARC4\n",
    "ciphers = ['AES', 'DES', '3DES', 'ARC4', 'BLOWFISH', 'CHACHA']\n",
    "\n",
    "analyze_cipher_distribution(2016, ciphers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual comparison with CCS 2013 benign dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some marginal functions for processing df_cipher\n",
    "def strip_get_instance(x):\n",
    "    prefix = 'Cipher.getInstance('\n",
    "    if x == prefix:\n",
    "        return 'obfuscated'\n",
    "\n",
    "    if str(x).startswith(prefix):\n",
    "        return str(x)[len(prefix) + 1:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def div_norm(x):\n",
    "    return int((15134 / 21649) * x)\n",
    "\n",
    "def rename_star_notation(x):\n",
    "    if x == 'AES':\n",
    "        return 'AES *'\n",
    "    if x == 'DES':\n",
    "        return 'DES *'\n",
    "    if x == 'DESede':\n",
    "        return 'DESede *'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worried about duplicates\n",
    "evaluator.df_records.shape\n",
    "evaluator.df_records.drop_duplicates(subset=['class_name', 'line', 'line_number']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.df_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers = evaluator.api_definition['encryption']['AES'] + evaluator.api_definition['encryption']['DES'] + ['Cipher.getInstance(']\n",
    "df_cipher = evaluator.df_records.loc[(evaluator.df_records.trigger.isin(triggers)) & (evaluator.df_records.year == 2012)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cipher.trigger = df_cipher.trigger.apply(strip_get_instance)\n",
    "df_cipher.trigger = df_cipher.trigger.apply(rename_star_notation)\n",
    "val_counts = df_cipher.trigger.value_counts()\n",
    "val_counts = val_counts.apply(div_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malicious DF\n",
    "malicious_df = val_counts.loc[val_counts > 10].to_frame(name='malicious_freq')\n",
    "\n",
    "# Benign df, the dictionary data are from the CryptoLint table paper\n",
    "benign_dict = {'AES/CBC/PKCS5Padding': 5878, 'AES *': 4803, 'DES/ECB/NoPadding': 1151, 'DES *': 741, 'DESede *': 501, 'DESede/ECB/PKCS5Padding': 473, 'AES/CBC/NoPadding': 468, 'AES/ECB/PKCS5Padding': 443, 'AES/CBC/PKCS7Padding': 235, 'DES/ECB/PKCS5Padding': 221, 'AES/ECB/NoPadding': 220, 'DES/CBC/PKCS5Padding': 205, 'AES/ECB/PKCS7Padding': 155, 'AES/CFB8/NoPadding': 104}\n",
    "benign_df = pd.Series(benign_dict).to_frame(name='benign_freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer join on malicious_df and benign_df, save to .csv\n",
    "comparison = malicious_df.join(benign_df, how='outer').fillna(0).sort_values(by=['malicious_freq', 'benign_freq'], ascending=False)\n",
    "comparison.malicious_freq = comparison.malicious_freq.astype('int64')\n",
    "comparison.benign_freq = comparison.benign_freq.astype('int64')\n",
    "comparison.drop(['obfuscated'])\n",
    "comparison.to_csv('/Users/adam/phd/projects/CryptoMalware/experiments/malicious_benign_comparison/comp.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('colheader_justify', 'center')\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "html_string = '''\n",
    "<html>\n",
    "  <head><title>HTML Pandas Dataframe with CSS</title></head>\n",
    "  <link rel=\"stylesheet\" type=\"text/css\" href=\"df_style.css\"/>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triggers(config_path):\n",
    "    with open(config_path, 'r') as handle:\n",
    "        stream = yaml.load(handle, Loader=yaml.FullLoader)\n",
    "    return stream['evaluate']['categories']\n",
    "\n",
    "def plot_message_digests(df_records, dataset_sizes, digest_triggers, output_folder, show=True):\n",
    "    def escape(string):\n",
    "        return string.replace('(', '\\(')\n",
    "\n",
    "    def craft_plot_labels(triggers, generic_trigger):\n",
    "        labels = {}\n",
    "        for x in triggers:\n",
    "            if x == generic_trigger:\n",
    "                labels[x] = ('obfuscated')\n",
    "            else:\n",
    "                labels[x] = x.split('MessageDigest.getInstance(\"')[1]\n",
    "        return labels\n",
    "    \n",
    "    def prepare_plot_paths(output_folder):\n",
    "        dgst_path = os.path.join(output_folder, 'digests')\n",
    "        if not os.path.exists(dgst_path):\n",
    "            os.mkdir(dgst_path)\n",
    "        \n",
    "        return os.path.join(dgst_path, 'year_distribution_bar.png'), os.path.join(dgst_path, 'year_distribution_line.png'), os.path.join(dgst_path, 'aggregated_distribution_bar.png'),\n",
    "    \n",
    "    def plot_year_line(df, filepath):\n",
    "        ax = sns.lineplot(x='year', y='norm_frequency', hue='trigger', data=df)\n",
    "        ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "        ax.xaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        ax.set(xlabel='Year', ylabel='Frequency per 10k samples', title='Popularity of hash functions over years')\n",
    "        ax.figure.savefig(filepath, dpi=300, format='png', bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        if show is True:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_year_bar(df, filepath):\n",
    "        ax = sns.catplot(x='trigger', y='norm_frequency', hue='year', data=df, kind='bar', aspect=3)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        ax.set(xlabel='Year', ylabel='Frequency per 10k samples', title='Popularity of hash functions over years')\n",
    "        plt.savefig(filepath, dpi=300, format='png', bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        if show is True:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_aggregated_bar(df, filepath):\n",
    "        ax = sns.barplot(x='trigger', y='norm_frequency', data=df)\n",
    "        ax.set(xlabel='Hash function', ylabel='frequency per 10k samples', title='Popularity of hash functions in all samples')\n",
    "        plt.savefig(filepath, dpi=300, format='png', bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        if show is True:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "            #ax.set(ylim=(0, 100))\n",
    "            #ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "            #ax.xaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "            #ax.set(xlabel='Year', ylabel='% of sample with crypto', title='Percentage of samples containing cryptographic API')\n",
    "\n",
    "        \n",
    "    escaped_triggers = [escape(x) for x in digest_triggers]\n",
    "    generic_trigger = digest_triggers[0]\n",
    "    plot_labels = craft_plot_labels(digest_triggers, generic_trigger)\n",
    "    year_bar, year_line, aggregated_bar = prepare_plot_paths(output_folder)\n",
    "    \n",
    "    df_digest = df_records[df_records.trigger.str.contains('|'.join(escaped_triggers))]\n",
    "    df_digest = df_digest.drop_duplicates(subset=['sha256', 'class_name', 'line_number'], keep='last')\n",
    "    df_digest.trigger = df_digest.trigger.map(plot_labels)\n",
    "    val_counts = df_digest.trigger.value_counts()\n",
    "    n_obfuscated = val_counts['obfuscated']\n",
    "    print(f'Out of {df_digest.shape[0]} unique hash function statements, {n_obfuscated} ({n_obfuscated * 100 / df_digest.shape[0]:.1f}%) is obfuscated')\n",
    "    print('-' * 80)\n",
    "    \n",
    "    norm_factor = {key: val / 10000 for key, val in dataset_sizes.items()}\n",
    "    df_processed = pd.DataFrame(df_digest.groupby('year').trigger.value_counts()).rename(columns={'trigger': 'frequency'}).reset_index()\n",
    "    df_processed['frequency'] = df_processed['frequency'].astype('float64')\n",
    "    df_processed['norm_frequency'] = df_processed['frequency'] / df_processed['year'].map(norm_factor)\n",
    "    df_processed['norm_frequency'] = df_processed['norm_frequency'].astype('int64')\n",
    "    df_processed.to_html(os.path.join(output_folder, 'digests/normalized_frequency.html'))\n",
    "    \n",
    "    plot_year_line(df_processed, year_line)\n",
    "    plot_year_bar(df_processed, year_bar)\n",
    "    plot_aggregated_bar(df_processed, aggregated_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ciphers(df_records, dataset_sizes, cipher_triggers, output_folder):\n",
    "    aes = ['obfuscated', 'AES', 'AES/CBC/ISO10126Padding', 'AES/CBC/NoPadding', 'AES/CBC/PKCS5Padding', 'AES/CFB/ISO10126Padding', 'AES/CFB/NoPadding', 'AES/CFB/PKCS5Padding', 'AES/CTR/ISO10126Padding', 'AES/CTR/NoPadding', 'AES/CTR/PKCS5Padding', 'AES/CTS/ISO10126Padding', 'AES/CTS/NoPadding', 'AES/CTS/PKCS5Padding', 'AES/ECB/ISO10126Padding', 'AES/ECB/NoPadding', 'AES/ECB/PKCS5Padding', 'AES/OFB/ISO10126Padding', 'AES/OFB/NoPadding', 'AES/OFB/PKCS5Padding', 'AES/GCM/NoPadding', 'AES_128', 'AES_128/CBC/NoPadding', 'AES_128/CBC/PKCS5Padding', 'AES_128/ECB/NoPadding', 'AES_128/ECB/PKCS5Padding', 'AES_128/GCM/NoPadding', 'AES_256', 'AES_256/CBC/NoPadding', 'AES_256/CBC/PKCS5Padding', 'AES_256/ECB/NoPadding', 'AES_256/ECB/PKCS5Padding', 'AES_256/GCM/NoPadding']\n",
    "    des = ['obfuscated', 'DES', 'DES/CBC/ISO10126Padding', 'DES/CBC/NoPadding', 'DES/CBC/PKCS5Padding', 'DES/CFB/ISO10126Padding', 'DES/CFB/NoPadding', 'DES/CFB/PKCS5Padding', 'DES/CTR/ISO10126Padding', 'DES/CTR/NoPadding', 'DES/CTR/PKCS5Padding', 'DES/CTS/ISO10126Padding', 'DES/CTS/NoPadding', 'DES/CTS/PKCS5Padding', 'DES/ECB/ISO10126Padding', 'DES/ECB/NoPadding', 'DES/ECB/PKCS5Padding', 'DES/OFB/ISO10126Padding', 'DES/OFB/NoPadding', 'DES/OFB/PKCS5Padding']\n",
    "    desede = ['obfuscated', 'DESede', 'DESede/CBC/ISO10126Padding', 'DESede/CBC/NoPadding', 'DESede/CBC/PKCS5Padding', 'DESede/CFB/ISO10126Padding', 'DESede/CFB/NoPadding', 'DESede/CFB/PKCS5Padding', 'DESede/CTR/ISO10126Padding', 'DESede/CTR/NoPadding', 'DESede/CTR/PKCS5Padding', 'DESede/CTS/ISO10126Padding', 'DESede/CTS/NoPadding', 'DESede/CTS/PKCS5Padding', 'DESede/ECB/ISO10126Padding', 'DESede/ECB/NoPadding', 'DESede/ECB/PKCS5Padding', 'DESede/OFB/ISO10126Padding', 'DESede/OFB/NoPadding', 'DESede/OFB/PKCS5Padding']\n",
    "    chacha = ['obfuscated', 'ChaCha20',  'ChaCha20/NONE/NoPadding', 'ChaCha20/Poly1305/NoPadding']\n",
    "    blowfish = ['obfuscated', 'BLOWFISH', 'BLOWFISH/CBC/ISO10126Padding', 'BLOWFISH/CBC/NoPadding', 'BLOWFISH/CBC/PKCS5Padding', 'BLOWFISH/CFB/ISO10126Padding', 'BLOWFISH/CFB/NoPadding', 'BLOWFISH/CFB/PKCS5Padding', 'BLOWFISH/CTR/ISO10126Padding', 'BLOWFISH/CTR/NoPadding', 'BLOWFISH/CTR/PKCS5Padding', 'BLOWFISH/CTS/ISO10126Padding', 'BLOWFISH/CTS/NoPadding', 'BLOWFISH/CTS/PKCS5Padding', 'BLOWFISH/ECB/ISO10126Padding', 'BLOWFISH/ECB/NoPadding', 'BLOWFISH/ECB/PKCS5Padding', 'BLOWFISH/OFB/ISO10126Padding', 'BLOWFISH/OFB/NoPadding', 'BLOWFISH/OFB/PKCS5Padding']\n",
    "    rc4 = ['obfuscated', 'ARC4', 'ARC4/ECB/NoPadding', 'ARC4/NONE/NoPadding']\n",
    "    rsa = ['obfuscated', 'RSA', 'RSA/ECB/NoPadding', 'RSA/ECB/OAEPPadding', 'RSA/ECB/PKCS1Padding', 'RSA/NONE/NoPadding', 'RSA/NONE/OAEPPadding', 'RSA/NONE/PKCS1Padding']\n",
    "    oeap = ['obfuscated', 'OAEPwithSHA-1andMGF1Padding', 'OAEPwithSHA-256andMGF1Padding', 'OAEPwithSHA-224andMGF1Padding', 'OAEPwithSHA-384andMGF1Padding', 'OAEPwithSHA-512andMGF1Padding']\n",
    "    primitives = {'aes': aes, 'des': des, 'desede': desede, 'chacha': chacha, 'blowfish': blowfish, 'rc4': rc4, 'rsa': rsa, 'oeap': oeap}\n",
    "    \n",
    "    \n",
    "    def parse_triggers(triggers):\n",
    "        triggers.remove('Cipher')\n",
    "        triggers.remove('DECRYPT_MODE')\n",
    "        triggers.remove('ENCRYPT_MODE')\n",
    "        triggers.remove('PRIVATE_KEY')\n",
    "        triggers.remove('PUBLIC_KEY')\n",
    "        triggers.remove('SECRET_KEY')\n",
    "        escaped_triggers = [escape(x) for x in triggers]\n",
    "        generic_trigger = triggers[0]\n",
    "        \n",
    "        return triggers, escaped_triggers, generic_trigger\n",
    "    \n",
    "    def escape(string):\n",
    "        return string.replace('(', '\\(')\n",
    "    \n",
    "    def map_defaults(x):\n",
    "        if str(x) == 'Cipher.getInstance(\"AES':\n",
    "            return 'Cipher.getInstance(\"AES/ECB/NoPadding'\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def strip_get_instance(x):\n",
    "        prefix = 'Cipher.getInstance('\n",
    "        if x == prefix:\n",
    "            return 'obfuscated'\n",
    "\n",
    "        if str(x).startswith(prefix):\n",
    "            return str(x)[len(prefix) + 1:]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def map_to_summary(x):\n",
    "        if x == 'obfuscated':\n",
    "            return x\n",
    "\n",
    "        for key, val in primitives.items():\n",
    "            if any([(trigger in x) for trigger in val]):\n",
    "                return key\n",
    "\n",
    "        return 'unknown trigger'\n",
    "    \n",
    "    def draw_line(df, category, out_dir):\n",
    "        ax = sns.lineplot(x='year', y='norm_frequency', hue='trigger', data=df)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        ax.set(xlabel='Year', ylabel='frequency per 10k samples', title=f'Popularity of {category} in all samples')\n",
    "        ax.figure.savefig(os.path.join(out_dir, 'year_distribution_line.png'), dpi=300, format='png', bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        plt.close()\n",
    "    \n",
    "    def draw_cat(df, category, out_dir):\n",
    "        ax = sns.catplot(x='trigger', y='norm_frequency', hue='year', kind='bar', data=df, aspect=3)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        ax.set(xlabel='Trigger', ylabel='frequency per 10k samples', title=f'Popularity of {category} primitive(s) per year.')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.savefig(os.path.join(out_dir, 'year_distribution_bar.png'), dpi=300, format='png', bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        plt.close()\n",
    "    \n",
    "    def draw_bar(df, category, out_dir):\n",
    "        ax = sns.barplot(x='trigger', y='norm_frequency', data=df)\n",
    "        ax.set(xlabel='Trigger', ylabel='frequency per 10k samples', title=f'Aggregated popularity of {category} primitive(s)')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.savefig(os.path.join(out_dir, 'aggregated_distribution_bar.png'), dpi=300, format='png', bbox_inches = 'tight', pad_inches = 0.1)\n",
    "        plt.close()\n",
    "    \n",
    "    def draw_plots(df, category, out_dir):\n",
    "        df_processed = pd.DataFrame(df.groupby('year').trigger.value_counts()).rename(columns={'trigger': 'frequency'}).reset_index()\n",
    "        df_processed['frequency'] = df_processed['frequency'].astype('float64')\n",
    "        df_processed['norm_frequency'] = df_processed['frequency'] / df_processed['year'].map(norm_factor)\n",
    "        df_processed['norm_frequency'] = df_processed['norm_frequency'].astype('float64')\n",
    "        df_processed.to_html(os.path.join(out_dir, 'normalized_frequency.html'))\n",
    "        \n",
    "        draw_line(df_processed, category, out_dir)\n",
    "        draw_cat(df_processed, category, out_dir)\n",
    "        draw_bar(df_processed, category, out_dir)\n",
    "    \n",
    "    def draw_all_categories(out_dir):\n",
    "        aes_path = os.path.join(out_dir, 'aes')\n",
    "        if not os.path.exists(aes_path):\n",
    "            os.mkdir(aes_path)\n",
    "        \n",
    "        des_path = os.path.join(out_dir, 'des')\n",
    "        if not os.path.exists(des_path):\n",
    "            os.mkdir(des_path)\n",
    "        \n",
    "        aes_ciphers = df_cipher.loc[df_cipher.trigger.str.contains('|'.join(aes))]\n",
    "        des_ciphers = df_cipher.loc[df_cipher.trigger.str.contains('|'.join(des))]\n",
    "        \n",
    "        draw_plots(aes_ciphers, 'AES', aes_path)\n",
    "        draw_plots(des_ciphers, 'DES', des_path)\n",
    "   \n",
    "    norm_factor = {key: val / 10000 for key, val in dataset_sizes.items()}\n",
    "    # makedirs\n",
    "    out_path = os.path.join(output_folder, 'cipher')\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "    \n",
    "    triggers, escaped_triggers, generic_trigger = parse_triggers(cipher_triggers)\n",
    "        \n",
    "    df_cipher = df_records.loc[df_records.trigger.str.contains('|'.join(escaped_triggers))]\n",
    "    df_cipher.trigger = df_cipher.trigger.map(map_defaults).map(strip_get_instance)\n",
    "    df_cipher = df_cipher.drop_duplicates(subset=['sha256', 'class_name', 'line_number'], keep='last')\n",
    "    val_counts = df_cipher.trigger.value_counts()\n",
    "    \n",
    "    summary_path = os.path.join(out_path, 'summary')\n",
    "    if not os.path.exists(summary_path):\n",
    "        os.mkdir(summary_path)\n",
    "    summary_ciphers = copy.deepcopy(df_cipher)\n",
    "    summary_ciphers.trigger = summary_ciphers.trigger.map(map_to_summary)\n",
    "    \n",
    "    n_obf = val_counts['obfuscated']\n",
    "    n_all = val_counts.sum()\n",
    "    print(f'Out of {n_all} unique cipher primitive statements, {n_obf} ({n_obf * 100 / n_all:.1f}%) is obfuscated')\n",
    "    print('-' * 80)\n",
    "    \n",
    "    draw_plots(summary_ciphers, 'All', summary_path)\n",
    "    draw_all_categories(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
