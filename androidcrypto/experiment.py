import functools
import logging
import os
import shutil
import sys
import json
from datetime import datetime, timedelta
from multiprocessing import Pool

import neptune
from stopit import SignalTimeout, TimeoutException

import androidcrypto.constants as constants
from androidcrypto.constants import StatusCode, EvaluateException, ThirdPartyException, DecompileException, \
    DownloadException, LabelException

from androidcrypto.workers.decompile import decompile_worker
from androidcrypto.workers.download import download_worker
from androidcrypto.workers.evaluate import evaluate_worker
from androidcrypto.workers.third_party import third_party_worker

logger = logging.getLogger(__name__)


class Experiment:
    def __init__(self, experiment_config):
        self.cfg = experiment_config
        self.dset = self.cfg.dset
        self.experiment = None

        self.experiment_id = 'untitled'
        self.start_time = datetime.now()
        self.last_update_time = datetime.now()
        self.progress_metric_name = 'progress'

        download_cfg = self.cfg.tasks.get(constants.TASK_DOWNLOAD, None)
        self.delete_apks = False
        if download_cfg is not None:
            self.delete_apks = download_cfg.delete_apks

        decompile_cfg = self.cfg.tasks.get(constants.TASK_DECOMPILE, None)
        self.delete_dxs = False
        if decompile_cfg is not None:
            self.delete_dxs = decompile_cfg.delete_dxs

    def init_neptune(self):
        if self.cfg.is_being_logged:
            try:
                neptune.init(project_qualified_name=self.cfg.neptune_project_name,
                             api_token=self.cfg.neptune_api_token)
                self.experiment = neptune.create_experiment(name=self.cfg.experiment_name)

                self.experiment.set_property(self.dset.name + ' version', self.dset.sha_digest)
            except Exception as e:
                logging.error(f'Failed to connect to the Neptune.ai: {e}')
            #self.experiment.append_tag(self.dset.name)

            self.cfg.experiment_id = str(self.experiment.id)

    def prepare_experiment(self):
        self.init_neptune()

        if constants.TASK_DOWNLOAD in self.cfg.tasks.keys():
            if self.dset.apk_available is True:
                logging.critical(f'Apks already available while trying to donwload others. Exiting.')
                sys.exit()
            self.dset.prepare_download(self.cfg.tasks[constants.TASK_DOWNLOAD])

        if constants.TASK_DECOMPILE in self.cfg.tasks.keys():
            if self.dset.dx_available is True:
                logging.critical(f'Error: dxs already available while trying to decompile. Exiting.')
                sys.exit()
            self.dset.prepare_dx_paths()

        if constants.TASK_THIRD_PARTY_LIBS in self.cfg.tasks.keys():
            self.dset.prepare_third_party_lib_paths()

        self.log_progress(force_log=True)

    def run(self):
        logging.info('Initializing experiment.')
        self.prepare_experiment()

        process_pool = Pool(self.cfg.n_threads)

        partial_worker = functools.partial(self.super_worker, tasks=self.cfg.tasks, timeout=self.cfg.timeout)

        logging.info(f'Established process pool with {self.cfg.n_threads} subprocesses. Starting processing {self.dset.n_samples} samples.')
        for sample_id, sample_record in self.dset.generator_json():
            process_pool.apply_async(partial_worker, (sample_id, sample_record, ), callback=self.super_worker_callback)

        process_pool.close()
        process_pool.join()

        logging.info(f'Successfully processed {self.dset.processed_samples_codes[StatusCode.OK]} out of {self.dset.n_samples} samples.')
        logging.info(f'Cleaning up after experiment.')
        self.finalize_experiment()

    def finalize_experiment(self):
        for status_code in StatusCode:
            logging.info(f'Number of samples with exit code {status_code.value}: {self.dset.processed_samples_codes[status_code]}.')

        if self.delete_apks is True and os.path.exists(self.dset.apk_path):
            shutil.rmtree(self.dset.apk_path)

        if self.delete_dxs is True and os.path.exists(self.dset.dx_path):
            shutil.rmtree(self.dset.dx_path)

        if self.delete_apks is False and (self.dset.apk_available is True or constants.TASK_DOWNLOAD in self.cfg.tasks.keys()):
            self.dset.apk_available = True
        if self.delete_dxs is False and (self.dset.dx_available is True or constants.TASK_DECOMPILE in self.cfg.tasks.keys()):
            self.dset.dx_available = True

        if constants.TASK_THIRD_PARTY_LIBS in self.cfg.tasks.keys():
            self.dset.delete_third_party_tmp_folder()

        if constants.TASK_LABEL in self.cfg.tasks.keys():
            try:
                self.label_samples()
            except LabelException:
                logging.error('Failed on labeling dataset.')
            except Exception as e:
                logging.error(f'Failed on uknown issue during dataset labeling: {e}.')

        self.log_progress(force_log=True)
        self.dset.clean_up_dataset()
        self.eval_neptune()
        self.delete_literadar_log()

    @staticmethod
    def super_worker(sample_id, sample_record, tasks, timeout=constants.TIMEOUT_CONSTANT):
        status_code = StatusCode.OK
        curr_time = datetime.now()

        with SignalTimeout(timeout):
            try:
                if constants.TASK_DOWNLOAD in tasks.keys():
                    androzoo_path = sample_record['metadata']['androzoo_url']
                    apk_path = sample_record['metadata']['apk_path']
                    download_worker(androzoo_path, apk_path)
                if constants.TASK_DECOMPILE in tasks.keys():
                    apk_path = sample_record['metadata']['apk_path']
                    dx_path = sample_record['metadata']['dx_path']
                    decompile_worker(apk_path, dx_path, tasks[constants.TASK_DECOMPILE].jadx_path)
                if constants.TASK_THIRD_PARTY_LIBS in tasks.keys():
                    third_party_worker(sample_record, tasks[constants.TASK_THIRD_PARTY_LIBS].literadar_path,
                                       tasks[constants.TASK_THIRD_PARTY_LIBS].crypto_libs)
                if constants.TASK_EVALUATE in tasks.keys():
                    evaluate_worker(sample_record, tasks[constants.TASK_EVALUATE].keywords, tasks[constants.TASK_EVALUATE].imports)

            except TimeoutException:
                logging.warning(f'Timeout on {sample_id} after {datetime.now() - curr_time} seconds.')
                status_code = StatusCode.FAILED_TIMEOUT
            except DownloadException:
                status_code = StatusCode.FAILED_ON_DOWNLOAD
            except DecompileException:
                status_code = StatusCode.FAILED_ON_DECOMPILE
            except ThirdPartyException:
                status_code = StatusCode.FAILED_ON_THIRD_PARTY
            except EvaluateException:
                status_code = StatusCode.FAILED_ON_EVALUATE
            except Exception:
                status_code = StatusCode.FAILED_UNKNOWN

            return status_code, sample_id, sample_record

    def super_worker_callback(self, result):
        status_code, sample_id, sample_record = result

        if constants.TASK_DOWNLOAD in self.cfg.tasks.keys():
            del sample_record['metadata']['androzoo_url']

        if self.delete_apks is True:
            self.dset.delete_apk(sample_id)
            del sample_record['metadata']['apk_path']

        if self.delete_dxs is True:
            self.dset.delete_dx(sample_id)
            del sample_record['metadata']['dx_path']

        if constants.TASK_THIRD_PARTY_LIBS in self.cfg.tasks.keys():
            self.dset.delete_third_party_tmp_file(sample_id)
            del sample_record['metadata']['third_party_tmp_path']

        if status_code == StatusCode.OK:
            self.dset.processed_json_data[sample_id] = sample_record
        else:
            self.dset.clean_up_record(sample_id)

        logging.debug(f'Finished on {sample_id} with {status_code}.')

        self.dset.n_processed_samples += 1
        self.dset.processed_samples_codes[status_code] += 1

        if not self.dset.n_processed_samples % constants.JSON_CHUNK_SIZE:
            self.dset.update_processed_data()
        self.log_progress()

    def label_samples(self):
        try:
            with open(self.cfg.tasks[constants.TASK_LABEL].euphony_names_path, 'r') as json_handle:
                euphony_names = json.load(json_handle)

            with open(self.cfg.tasks[constants.TASK_LABEL].euphony_types_path, 'r') as json_handle:
                euphony_types = json.load(json_handle)
        except OSError:
            raise LabelException

        for sample_id, sample_record in self.dset.generator_processed_json():
            sample_record['metadata']['euphony_name'] = euphony_names.get(sample_id.lower(), None)
            sample_record['metadata']['euphony_type'] = euphony_types.get(sample_id.lower(), None)

    def log_progress(self, force_log=False):
        if self.cfg.is_being_logged is True and (datetime.now() - self.last_update_time > timedelta(seconds=50) or force_log is True):
            self.last_update_time = datetime.now()
            fraction = self.dset.n_processed_samples / self.dset.n_samples
            try:
                self.experiment.log_metric(self.progress_metric_name, (self.last_update_time - self.start_time).total_seconds(), y=fraction)
                self.log_processed_samples()
            except Exception as e:
                logging.error(f'Error when reporting progress to neptune: {e}')

    def log_processed_samples(self):
        for status_code in StatusCode:
            self.experiment.log_metric(status_code.value, self.dset.processed_samples_codes[status_code])

    def eval_neptune(self):
        if self.cfg.is_being_logged:

            n_failed_samples = 0
            for key, val in self.dset.processed_samples_codes.items():
                if key != StatusCode.OK:
                    n_failed_samples += val
            try:
                neptune.log_artifact(self.cfg.config_path)
                neptune.log_artifact(constants.LOGS_FILENAME)
                neptune.log_metric('Total_n_failed_samples', n_failed_samples)
                neptune.stop()
            except Exception as e:
                logging.error(f'Error when evaluating neptune experiment: {e}')

    @staticmethod
    def delete_literadar_log():
        try:
            os.remove('./log_libradar.txt')
        except OSError:
            logging.warning('Libradar log was not found thus was not deleted.')
