import os
import androidcrypto.constants as constants
from importlib import reload
import logging
import neptune
from time import gmtime, strftime
from datetime import datetime, timedelta
from multiprocessing import Pool
from tqdm import tqdm


class Task:
    """
    Partially abstract class. It covers general case of running a task that comprises of:
    1) Initializing Neptune.ml experiment and local folder with results
    2) running the experiment on each of the datasets
        - where 'running on a dataset' is an abstract function
    3) Uploading the experiment artifacts to the Neptune.ml service
    4) Terminating the experiment

    Specific cases are extended by child classes
    """
    def __init__(self, experiment_config):
        self.cfg = experiment_config
        self.current_dataset = None
        self.experiment = None
        self.experiment_id = 'untitled'
        self.processed_samples = 0
        self.dset_start_time = datetime.now()
        self.last_update_time = datetime.now()
        self.pbar = None
        self.progress_metric_name = 'progress'

    def init_neptune(self):
        """
        Creates new Neptune experiment and prepares folder to store results into
        """
        if self.cfg.is_being_logged:
            logging.info('Creating neptune experiment')
            neptune.init(project_qualified_name=self.cfg.neptune_project_name,
                         api_token=self.cfg.neptune_api_token)
            self.experiment = neptune.create_experiment(name=self.cfg.experiment_name)

            for dset in self.cfg.datasets:
                self.experiment.set_property(dset.name + ' version', dset.sha_digest)
                self.experiment.append_tag(dset.name)

            self.cfg.experiment_id = str(self.experiment.id)
            self._update_folder_structure(self.cfg.experiment_id)

        else:
            suffix_dirname = strftime("%Y%m%dt%H%M%S", gmtime())
            self._update_folder_structure(suffix_dirname)

    def _update_folder_structure(self, suffix_dirname):
        """
        Moves folder from temporary path to the folder with the ID of the experiment
        """
        logging.info('Updating folder structure.')
        old_logging_path = self.cfg.logging_path
        self.cfg.output_path = os.path.join(self.cfg.output_path, suffix_dirname)
        os.mkdir(self.cfg.output_path)
        self.cfg.logging_path = os.path.join(self.cfg.output_path, constants.LOGS_FILENAME)
        self._move_logging(old_logging_path, self.cfg.logging_path)

    @staticmethod
    def _move_logging(src, dst):
        """
       Moves logging file from src filepath to dst filepath (done when folder with results is established).
       :param src: destination to move from
       :param dst: destination to move to
       :return: Nothing
       """
        reload(logging)
        os.rename(src, dst)
        logging.basicConfig(filename=dst, level=logging.INFO, filemode='a',
                            format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s')

    def run(self):
        """
        Runs the experiment on all datasets
        :return:
        """
        self.init_neptune()
        for dset in self.cfg.datasets:
            self.current_dataset = dset
            self.run_on_dataset(dset)
            self.clean_up_after_dataset()
        self.eval_neptune()

    def run_on_dataset(self, dset):
        """
        Runs the experiment on a single dataset. In exact, spawns specified number of subprocesses as workers
        and begins with asynchronous application of worker functions on those. This progress is being monitored by a
        'progress' metric in neptune.ml that spans from 0 to 1 and tells the operator how much has already been done.
        Note that the callback is run after each evaluation of the function.
        :param dset: dataset to perform the analysis on
        :return:
        """
        self.dset_start_time = datetime.now()
        self.progress_metric_name = 'progress_' + self.current_dataset.name
        if self.cfg.is_being_logged is True:
            self.update_neptune_progress()

        process_pool = Pool(self.cfg.n_threads)
        with tqdm(total=self.current_dataset.n_samples) as self.pbar:
            for smpl in dset.generator():
                process_pool.apply_async(self.worker, (smpl,), callback=self.worker_callback)
            process_pool.close()
            process_pool.join()

        if self.cfg.is_being_logged is True:
            self.update_neptune_progress()

    # IMPORTANT: Any implementation must implement this as a static method, otherwise, parallelism will fail.
    @staticmethod
    def worker(sample):
        """
        This function is abstract. This is the actual task being worked on.
        :param sample: the sample to work on
        :return: Whatever, is handled in the callback
        """
        raise NotImplementedError('Abstract method -- not meant to be implemented.')

    def clean_up_after_dataset(self):
        """
        To be implemented in the child classes. Could be e.g. set number of failed samples to 0, restart clock, etc.
        :return:
        """
        self.processed_samples = 0
        self.progress_metric_name = 'progress'

    def worker_callback(self, result):
        """
        In general case it only maintains offline (in cmdline) and online (in Neptune.ml) progress bar. Whatever needs
        to be done with the results of worker should be implemented in the child classes. The Neptune.ml progress bar
        is quite heavy, we send each 50 samples by default.
        :param result: result
        :return: Nothing
        """
        self.pbar.update()
        # TODO: Maybe decrease granularity if the load is too heavy on time
        if self.cfg.is_being_logged is True and (datetime.now() - self.last_update_time) > timedelta(seconds=20):
            self.update_neptune_progress()
            self.last_update_time = datetime.now()
        self.processed_samples += 1

    def update_neptune_progress(self):
        """
        :return: Updates Neptune.ml progress bar. Done in a form of uploading a metric that spans from 0 to 1 in time.
        On x axis, we have iterations.
        """
        curr_time = datetime.now()
        fraction = self.processed_samples / self.current_dataset.n_samples
        self.experiment.log_metric(self.progress_metric_name, (curr_time - self.dset_start_time).total_seconds(), y=fraction)

    def eval_neptune(self):
        """
        Uploads the experiment artifacts into the Neptune.ml
        :return:
        """
        if self.cfg.is_being_logged:
            self.cfg.logger.info('Uploading experiment to Neptune.ml')
            neptune.send_artifact(self.cfg.logging_path)
            neptune.send_artifact(self.cfg.config_path)
            neptune.stop()
