from androidcrypto.analyzers.task import Task
import os
import logging
import neptune
from androidcrypto.dataset import  DatasetException
import lzma
import pickle
from androguard import misc
from multiprocessing import Pool
from datetime import datetime
from tqdm import tqdm
import shutil
import androidcrypto.helpers as helpers

from androguard.core.bytecodes.apk import APK
from androguard.core.bytecodes.dvm import DalvikVMFormat
from androguard.core.analysis.analysis import Analysis
from androguard.decompiler.decompiler import DecompilerJADX


class TransformDatasets(Task):
    def __init__(self, experiment_config):
        super().__init__(experiment_config)
        self.failed_samples = []
        self.total_failed_samples = 0
        self.total_samples = 0
        self.current_dset_new_path = None

        self.custom_jadx_path = None
        self.prepare_jadx_binary()

        self.delete_apks = self.cfg.stream['delete_apks']

        self.home_packages = {}

    def prepare_jadx_binary(self):
        if 'jadx_path' in self.cfg.stream:
            self.custom_jadx_path = self.cfg.stream['jadx_path']
        else:
            self.custom_jadx_path = 'jadx'
        if not shutil.which(self.custom_jadx_path):
            raise Exception(f'Jadx binary not found in the path {self.custom_jadx_path}.')

    def init_neptune(self):
        super().init_neptune()
        if self.cfg.is_being_logged:
            self.experiment.append_tag('decompile')

    def run_on_dataset(self, dset):
        dset.prepare_dx_paths()

        self.dset_start_time = datetime.now()
        self.progress_metric_name = 'progress_' + self.current_dataset.name
        self.total_samples += self.current_dataset.n_samples
        self.update_neptune_progress()

        self.cfg.logger.info('Initializing decompiler class')
        self.cfg.logger.info(f'Running decompiler on {dset.name} dataset.')
        self.cfg.logger.setLevel(logging.ERROR)  # Warning: Changing this to logging.INFO significantly slows down the code.

        process_pool = Pool(self.cfg.n_threads)
        with tqdm(total=dset.n_samples) as self.pbar:
            for smpl in dset.generator_id_apk_dx():
                process_pool.apply_async(self.new_worder_jadx, (smpl[0], smpl[1], smpl[2], self.custom_jadx_path, ),
                                         callback=self.new_worker_callback)
            process_pool.close()
            process_pool.join()

        self.cfg.logger.setLevel(logging.INFO)
        self.cfg.logger.info(f'Decompilation failed on {len(self.failed_samples)} samples')
        for sample in self.failed_samples:
            self.cfg.logger.info(f'Decompilation failed on: {sample}')

        dset.update_after_decompilation()

        self.update_neptune_progress()

    @staticmethod
    def new_worder_jadx(sample_id, apk_path, dx_path, custom_jadx_path):
        try:
            a = APK(apk_path)
            d = DalvikVMFormat(a)
            dx = Analysis(d)
            d.set_decompiler(DecompilerJADX(d, dx, jadx=custom_jadx_path))
            dx.create_xref()

            if len(dx.classes) > 0:
                with lzma.open(dx_path, 'wb') as handle:
                    pickle.dump(dx, handle)

            return sample_id, helpers.get_reachable_methods(a, dx)

        except Exception:
            return sample_id, None

    def new_worker_callback(self, result):
        if result[1] is not None:
            self.current_dataset.json_data[result[0]]['decompilation'] = result[1]
            if self.delete_apks:
                self.current_dataset.delete_apk(result[0])
        else:
            self.failed_samples.append(result[0])
            self.total_failed_samples += 1
            self.current_dataset.delete_record(result[0])

        super().worker_callback(result)

    def eval_neptune(self):
        if self.cfg.is_being_logged is True:
            failed_samples_ratio = str(self.total_failed_samples) + '/' + str(self.total_samples)
            neptune.log_text('total_failed_samples', failed_samples_ratio)
        super().eval_neptune()

    def clean_up_after_dataset(self):
        if self.cfg.is_being_logged is True:
            failed_samples_ratio = str(len(self.failed_samples)) + '/' + str(self.current_dataset.n_samples)
            neptune.log_text(self.current_dataset.name + '_failed_samples', failed_samples_ratio)
        self.failed_samples = []
        super().clean_up_after_dataset()
