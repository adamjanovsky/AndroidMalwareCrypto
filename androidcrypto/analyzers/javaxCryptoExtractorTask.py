from androidcrypto.analyzers.task import Task
import androidcrypto.helpers as helpers
import yaml
import pandas as pd
from multiprocessing import Pool
from tqdm import tqdm
import os


class ExtractJavaxCrypto(Task):
    """
    Task to transform apk dataset into lzma dataset.
    """
    def __init__(self, experiment_config):
        super().__init__(experiment_config)
        self.keywords = self.identify_keywords(self.cfg.config_path)
        self.df = pd.DataFrame(columns=self.keywords)
        self.df_triggered = None
        self.triggered_data = []

    def identify_keywords(self, config_path):
        with open(config_path) as stream:
            config_stream = yaml.load(stream, Loader=yaml.FullLoader)
            return config_stream['javax_extractor']['strings_to_search']

    def init_neptune(self):
        super().init_neptune()
        if self.cfg.is_being_logged:
            self.experiment.append_tag('decompile')

    def run_on_dataset(self, dset):
        if dset.format == 'apk':
            print('will not work man...')

        process_pool = Pool(self.cfg.n_threads)
        with tqdm(total=self.current_dataset.n_samples) as self.pbar:
            for smpl, path in dset.generator_tuple():
                process_pool.apply_async(self.worker, (smpl, path, self.keywords,), callback=self.worker_callback)
            process_pool.close()
            process_pool.join()

        if self.cfg.is_being_logged is True:
            self.update_neptune_progress()

    @staticmethod
    def worker(sample, path, keywords):
        trigger_result = []
        result = [0] * len(keywords)
        classes = sample.get_classes()
        lines = []
        try:
            for cls in classes:
                src_class = helpers.extract_class_source_code(cls)
                if src_class is None:
                    continue
                for i, line in enumerate(src_class.split('\n')):
                    for wrd, rs in zip(keywords, result):
                        if wrd in line:
                            trigger_result.append([path, cls.name, wrd, line, i])

            #print(result)
            return trigger_result
        except Exception:
            print('error')

    def worker_callback(self, result):
        #self.df.append(result)
        self.triggered_data.extend([smpl for smpl in result])
        super().worker_callback(result)

    def eval_neptune(self):
        super().eval_neptune()

    def clean_up_after_dataset(self):
        self.df_triggered = pd.DataFrame(columns=['path', 'class', 'triggered by', 'line', 'line_number'], data=self.triggered_data)
        self.df_triggered.to_csv(os.path.join(self.cfg.output_path, 'results' + self.current_dataset.name + '.csv'))
        super().clean_up_after_dataset()


"""
class ComputeStringStatistics(Task):
    def __init__(self, jadx, apks_to_search, output_path, strings_to_search=None, count_imports=True):
        self.jadx = jadx
        self.strings_to_search = strings_to_search
        self.apks_to_search = apks_to_search
        self.count_imports = count_imports

        self.csv_filename = helpers.establish_results_filepath(output_path, 'results', 'csv')
        self.failed_files_filename = helpers.establish_results_filepath(output_path, 'failed_files', 'txt')

        self.occurrences_counter = pd.DataFrame(0, index=np.arange(len(self.apks_to_search)), columns=self.strings_to_search)
        self.occurrences_counter['file'] = [os.path.basename(x) for x in self.apks_to_search]
        cols = self.occurrences_counter.columns.tolist()
        cols = cols[-1:] + cols[:-1]
        self.occurrences_counter = self.occurrences_counter[cols]

    def run(self):
        correctly_processed = []

        with open(self.failed_files_filename, 'w') as f:
            for i, apk in tqdm(enumerate(self.apks_to_search)):
                if not self.count_occurrences_in_code(apk, i):
                    f.write(f'{apk}\n')
                    print(os.path.basename(apk))
                    self.occurrences_counter = self.occurrences_counter[self.occurrences_counter.file != os.path.basename(apk)]
                else:
                    correctly_processed.append(apk)

        family_names = [helpers.get_apk_label(path) for path in correctly_processed]
        sum_row = {self.occurrences_counter.columns.tolist()[0]: len(self.apks_to_search)}

        for col in self.occurrences_counter.columns.tolist()[1:]:
            sum_row[col] = self.occurrences_counter[col].sum()
        sum_row['family_name'] = 0
        sum_df = pd.DataFrame(sum_row, index=["sum"])

        # add the family name column
        self.occurrences_counter['family_name'] = family_names

        self.occurrences_counter = self.occurrences_counter.append(sum_df)
        self.occurrences_counter.to_csv(self.csv_filename, index=False, sep=';')

    def count_occurrences_in_code(self, apk, i):
        try:
            decompiler = self.jadx.load(apk)
        except:
            return False

        for cls in decompiler.classes:
            if cls.fullname.split('.')[0] == 'android':
                continue
            for line in cls.code.split('\n'):
                for s in self.strings_to_search:
                    if s not in line:
                        continue
                    if not self.count_imports and line.split(' ') and line.split(' ')[0] == 'import':
                        continue
                    self.occurrences_counter.at[i, s] += 1
        return True
"""
