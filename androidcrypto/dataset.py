import os
from collections import OrderedDict
import yaml
import json
from copy import deepcopy
import csv
import tempfile
import shutil
import sys
import logging

import androidcrypto.constants
from androidcrypto import helpers, constants


class DatasetException(Exception):
    pass


class Dataset:
    def __init__(self, root_path):
        self.root_path = root_path
        self.meta_path = os.path.join(self.root_path, constants.META_FILENAME)
        self.json_path = os.path.join(self.root_path, constants.JSON_FILENAME)
        self.processed_json_path = os.path.join(self.root_path, constants.PROCESSED_JSON_FILENAME)
        self.data_path = os.path.join(self.root_path, constants.DATA_DIRNAME)
        self.apk_path = os.path.join(self.data_path, constants.APK_DIRNAME)
        self.dx_path = os.path.join(self.data_path, constants.DX_DIRNAME)
        self.third_party_tmp_path = None

        self.json_data = OrderedDict()
        self.processed_json_data = OrderedDict()
        self.sample_ids = []

        self.apk_available = False
        self.dx_available = False
        self.sha_digest = 'So far not implemented'

        self.name = None
        self.description = None
        self.format = None
        self.androzoo_config = None

        self.n_samples = 0
        self.n_processed_samples = 0
        self.processed_samples_codes = {x: 0 for x in androidcrypto.constants.StatusCode}

        self._init_dataset()

    def generator_json(self):
        for key, val in self.json_data.items():
            yield key, val

    def clean_up_dataset(self):
        self.update_processed_data(final=True)
        self._update_n_samples()
        self._update_meta()

    def update_processed_data(self, final=False):
        # TODO: Currently slow way, must load all data into the memory.
        with open(self.processed_json_path) as handle:
            data = json.load(handle)

        data.update(self.processed_json_data)

        if final is True:
            with open(self.json_path, 'w') as handle:
                json.dump(data, handle)
            self.json_data = data
            try:
                os.remove(self.processed_json_path)
            except OSError:
                pass
        else:
            with open(self.processed_json_path, 'w') as handle:
                json.dump(data, handle)

        self.processed_json_data = OrderedDict()

    def _init_dataset(self):
        if os.path.isfile(self.meta_path) and os.path.isfile(self.json_path):
            self._load_dataset()
        else:
            self._create_dataset()

        self._update_n_samples()
        self.sample_ids = list(self.json_data.keys())
        self._create_processed_samples_file()
        self._update_meta()
        logging.info('Correctly initialized the dataset.')

    def _update_n_samples(self):
        self.n_samples = len(self.json_data.keys())

    def _create_dataset(self):
        if not os.path.exists(self.root_path):
            os.makedirs(self.root_path)

        self.name = 'Pick your dataset name here'
        self.description = 'Put your dataset description here'
        self.apk_available = False
        self.dx_available = False
        self.n_samples = 0

        for root, dir, files in os.walk(self.apk_path):
            dir_apks = [os.path.join(root, f) for f in files if f.endswith('apk')]

            for apk in dir_apks:
                sha = helpers.hash_file(apk)
                data = deepcopy(constants.DATASET_BASE_DICT)
                data['metadata']['apk_path'] = apk
                self.json_data[sha] = data

    def _load_dataset(self):
        with open(self.meta_path, 'r') as meta_file:
            config = yaml.load(meta_file, Loader=yaml.FullLoader)
            self.name = config['dataset_name']
            self.description = config['description']
            self.apk_available = config['apk_available']
            self.dx_available = config['dx_available']
            self.n_samples = config['n_samples']
        with open(self.json_path, 'r') as json_file:
            self.json_data = json.load(json_file)

    def _update_meta(self):
        with open(self.meta_path, 'w') as meta_file:
            config = {'dataset_name': self.name,
                      'description': self.description,
                      'n_samples': self.n_samples,
                      'apk_available': self.apk_available,
                      'dx_available': self.dx_available}
            yaml.dump(config, meta_file)

    def _update_json_data(self):
        with open(self.json_path, 'w') as handle:
            json.dump(self.json_data, handle)

    def _create_processed_samples_file(self):
        with open(self.processed_json_path, 'w') as handle:
            json.dump(self.processed_json_data, handle)

    def _update_hash(self):
        pass
        # self.sha_digest = dirhash(self.data_path, 'sha256')
        # self.config['sha_256'] = self.sha_digest

    def clean_up_record(self, sample_id):
        self.delete_apk(sample_id)
        self.delete_dx(sample_id)

    def delete_apk(self, sample_id):
        # TODO: Should check if last apk in nested subfolder. If yes, delete as well.
        try:
            os.remove(self.json_data[sample_id]['metadata']['apk_path'])
        except OSError:
            pass

    def delete_dx(self, sample_id):
        # TODO: Should check if last apk in nested subfolder. If yes, delete as well.
        dx_path = self.json_data[sample_id]['metadata']['dx_path']
        try:
            os.remove(dx_path)
        except OSError:
            pass

    def delete_third_party_tmp_file(self, sample_id):
        try:
            os.remove(self.json_data[sample_id]['metadata']['third_party_tmp_path'])
        except OSError:
            pass

    def _set_apk_path(self, sample_id, path):
        self.json_data[sample_id]['metadata']['apk_path'] = path

    def _set_dx_path(self, sample_id, path):
        self.json_data[sample_id]['metadata']['dx_path'] = path

    def prepare_apk_paths(self):
        os.makedirs(self.apk_path, exist_ok=True)
        for sample_id, json_record in self.generator_json():
            apk_path = os.path.join(self.apk_path, sample_id + '.apk')
            self._set_apk_path(sample_id, apk_path)

    def prepare_dx_paths(self):
        for sample_id, json_record in self.generator_json():
            apk_path = json_record['metadata']['apk_path']
            relative_directory = os.path.dirname(os.path.relpath(apk_path, self.apk_path))
            dir_to_create = os.path.join(self.dx_path, relative_directory)
            os.makedirs(dir_to_create, exist_ok=True)
            new_dx_path = os.path.join(dir_to_create, os.path.basename(apk_path).split('.apk')[0] + '.lzma')
            self._set_dx_path(sample_id, new_dx_path)

    def prepare_download(self, download_config):
        samples_to_download = self._filter_androzoo_dataset(download_config.n_samples, download_config.csv_path,
                                                            download_config.start_year, download_config.end_year,
                                                            download_config.minimal_vt_positives, download_config.max_size,
                                                            download_config.strategy)
        for sample in samples_to_download:
            download_url = self._get_androzoo_url(sample['sha256'], download_config.api_token)
            self.json_data[sample['sha256']] = deepcopy(constants.DATASET_BASE_DICT)
            self.json_data[sample['sha256']]['metadata']['androzoo_url'] = download_url
            self.json_data[sample['sha256']]['metadata']['vt_scan_year'] = self._androzoo_parse_year(sample['vt_scan_date'])

        self.n_samples = len(samples_to_download)
        self.sample_ids = list(self.json_data.keys())
        self.prepare_apk_paths()

    @staticmethod
    def _filter_androzoo_dataset(n_samples, csv_path, vt_scan_date_start, vt_scan_date_end, vt_treshold, max_size, strategy):
        samples_of_interest = []

        if strategy == constants.DOWNLOAD_STRATEGY_UNIFORM:
            n_buckets = vt_scan_date_end - vt_scan_date_start + 1
            bucket_size = n_samples // n_buckets
            remainder = n_samples % n_buckets

            buckets = {key: bucket_size for key in range(vt_scan_date_start, vt_scan_date_end + 1)}
            for year in buckets.keys():
                if remainder > 0:
                    buckets[year] += 1
                    remainder -= 1
                else:
                    break

        else:
            print('Not implemented yet, exiting.')
            sys.exit()

        with open(csv_path, 'r') as csv_handle:
            reader = csv.DictReader(csv_handle)
            sampled = 0

            for row in reader:
                if row['vt_detection'] != '':
                    virus_total = int(row['vt_detection'])
                else:
                    virus_total = 0

                vt_scan_year = row['vt_scan_date'].split('-')[0]
                if vt_scan_year != '':
                    vt_scan_year = int(vt_scan_year)
                else:
                    vt_scan_year = 0

                file_size = int(row['apk_size'])

                if virus_total >= vt_treshold and buckets.get(vt_scan_year, 0) > 0 and file_size < max_size:
                    samples_of_interest.append(row)
                    sampled += 1
                    buckets[vt_scan_year] -= 1

                if sampled >= n_samples:
                    return samples_of_interest

        return samples_of_interest

    @staticmethod
    def _androzoo_parse_year(vt_scan_date):
        return int(vt_scan_date.split('-')[0]) if vt_scan_date.split('-')[0] != '' else 0

    @staticmethod
    def _get_androzoo_url(sha256, api_key):
        return 'https://androzoo.uni.lu/api/download?apikey=' + api_key + '&sha256=' + sha256

    def prepare_third_party_lib_paths(self):
        self.third_party_tmp_path = tempfile.mkdtemp()
        for sample_id, json_record in self.generator_json():
            third_party_tmp_path = os.path.join(self.third_party_tmp_path, str(sample_id) + '.json')
            json_record['metadata']['third_party_tmp_path'] = third_party_tmp_path

    def delete_third_party_tmp_folder(self):
        shutil.rmtree(self.third_party_tmp_path)
