"""
File contains functions that can be used to train Decision List Classifier.
Decision List Classifier is a wrapper around Skope Rules.

Warning: this works only for binary classification

Author: Dominik Macko
"""

from typing import Dict, Any, Union, Callable, Tuple, List, Optional
from functools import partial

import numpy as np
import pandas as pd
from interpret.glassbox import DecisionListClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import make_scorer, f1_score, get_scorer
import optuna
import joblib

from .generic import train_model, train_randomizedsearchcv_model, train_gridsearchcv_model
from .utils import is_multiclass, get_feature_types, compute_balanced_class_weights_array, cross_val_score_weighted
from .config import TrainingTaskConfig

def decision_list_best_params_surroundings(best_params: Dict[str, Any]) -> Dict[str, Any]:
    """Get best parameters surroundings for random forest."""
    
    min_samples_split = best_params["min_samples_split"]
    max_depth = best_params["max_depth"]
    n_estimators = best_params["n_estimators"]
    max_samples = best_params["max_samples"]
    max_sample_features = best_params["max_sample_features"]

    best_params["min_samples_split"] = [min_samples_split - 1, min_samples_split, min_samples_split + 1]
    best_params["max_depth"] = [max_depth - 1, max_depth, max_depth + 1]
    best_params["n_estimators"] = [n_estimators - 1, n_estimators, n_estimators + 1]
    best_params["max_samples"] = [max(0.0, max_samples - 0.05), max_samples, min(max_samples + 0.05, 1.0)]
    best_params["max_sample_features"] = [max(0.0, max_sample_features - 0.05), max_sample_features, min(max_sample_features + 0.05, 1.0)]
    return best_params

def train_decision_list(train_X: np.array,
                        train_y: np.array,
                        scoring: Union[str, Callable[[Any, np.array, np.array], int]]="f1_weighted",
                        n_jobs: int=8,
                        verbose: int=3,
                        seed: int=42,
                        cv_splits: int=5,
                        precision_min: float=0.5,
                        recall_min: float=0.01,
                        max_features: str="sqrt",
                        feature_names: Optional[List[str]]=None,
                        feature_types: Optional[List[str]]=None 
                       ) -> Tuple[DecisionListClassifier, pd.DataFrame]:
    """Trains random forest classifier by searching for optimal alpha smoothing term.
    
    train_X - training set features
    train_y - training set targets
    scoring - scikit scoring function to use
    n_jobs - threads to use
    seed - seed to use
    verbose - scikit verbose level
    
    returns (Decision List Classifier, history dataframe)
    """
    
    grid = {
        "n_estimators": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21],
        "max_samples": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        "max_sample_features": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        "bootstrap": [True, False],
        "max_depth": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21],
        "min_samples_split": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]
    }
    return train_model(
        DecisionListClassifier(
            n_jobs=n_jobs, 
            random_state=seed,
            feature_names=feature_names,
            feature_types=feature_types,
            max_features=max_features,
            precision_min=precision_min,
            recall_min=recall_min
            ),
        train_randomizedsearchcv_model,
        train_gridsearchcv_model,
        grid,
        decision_list_best_params_surroundings,
        train_X,
        train_y,
        scoring=scoring,
        n_jobs=n_jobs,
        verbose=verbose,
        seed=seed,
        cv_splits=cv_splits
    )

class DecisionListObjective:
    """Decision List Objective used for Optuna library to optimize"""
    
    def __init__(
        self,
        train_X: Union[pd.DataFrame, np.array],
        train_y: Union[pd.Series, np.array],
        scorer: Union[Callable[[Union[np.array, pd.Series], Union[np.array, pd.Series]], float], str],
        n_jobs: int=8,
        seed: int=42,
        cv_splits: int=5,
        precision_min: float=0.5,
        recall_min: float=0.01,
        max_features: str="sqrt",
        feature_names: Optional[List[str]]=None,
        feature_types: Optional[List[str]]=None 
    ):
        """Initializes the objective
        
        train_X - training set features
        train_y - training set targets
        scorer - callable used to score performance (maximize)
        n_jobs - threads to use
        seed - random seed to use
        class_weight - class weight passed to RandomFOrestClassifier init
        n_estimators - trees to use
        """

        self.train_X = train_X
        self.train_y = train_y
        self.weights = compute_balanced_class_weights_array(train_y)
        self.scorer = get_scorer(scorer) if isinstance(scorer, str) else make_scorer(scorer)
        self.n_jobs = n_jobs
        self.seed = seed
        self.cv = StratifiedKFold(n_splits=cv_splits, random_state=seed, shuffle=True)
        self.precision_min = precision_min
        self.recall_min = recall_min
        self.max_features = max_features
        self.feature_names = feature_names
        self.feature_types = feature_types
        
    def best_model_callback(self,
                            study: optuna.study.Study,
                            trial: optuna.trial.Trial
                           ) -> None:
        """Callback that can be used to store the best model in the study."""
        
        if study.best_trial.number == trial.number:
            study.set_user_attr(key="best_model", value=trial.user_attrs["model"])
    
    def __call__(self, trial: optuna.trial.Trial) -> float:
        """Calls the objective to optimize it.
        
        trial - Optuna trial
        
        returns the scorer score on validation set
        """
        
        max_samples = trial.suggest_float("max_samples", 0.1, 1.0)
        max_sample_features = trial.suggest_float("max_sample_features", 0.1, 1.0)
        min_samples_split = trial.suggest_int("min_samples_split", 2, 25)
        max_depth = trial.suggest_int("max_depth", 2, 25)
        n_estimators = trial.suggest_int("n_estimators", 2, 25)
        bootstrap = trial.suggest_categorical("bootstrap", [True, False])

        dl = DecisionListClassifier(
            n_jobs=self.n_jobs, 
            random_state=self.seed,
            feature_names=self.feature_names,
            feature_types=self.feature_types,
            max_features=self.max_features,
            precision_min=self.precision_min,
            recall_min=self.recall_min,
            # hyperparameters
            max_samples=max_samples,
            max_sample_features=max_sample_features,
            min_samples_split=min_samples_split,
            max_depth=max_depth,
            n_estimators=n_estimators,
            bootstrap=bootstrap
        )
        
        metric = cross_val_score_weighted(dl, self.train_X, self.train_y, self.weights, scoring=self.scorer, cv=self.cv)
        dl.fit(self.train_X, self.train_y)
        trial.set_user_attr(key="model", value=dl)
        return metric

def train_decision_list_optuna(train_X: Union[pd.DataFrame, np.array],
                               train_y: Union[pd.Series, np.array],
                               scorer: Union[Callable[[Union[np.array, pd.Series], Union[np.array, pd.Series]], float], str],
                               study_name: str="decision_list",
                               n_jobs: int=8,
                               seed: int=42,
                               n_trials: int=100,
                               cv_splits: int=5,
                               precision_min: float=0.5,
                                recall_min: float=0.01,
                                max_features: str="sqrt",
                                feature_names: Optional[List[str]]=None,
                                feature_types: Optional[List[str]]=None 
                              ) -> Tuple[DecisionListClassifier, optuna.study.Study]:
    """Trains Decision List using Optuna.
    
    train_X - training set features
    train_y - training set targets
    scorer - callable that is used to score the performance
    study_name - Optuna study name
    n_jobs - threads to use
    seed - random seed to use
    n_trials - maximum trials
    
    returns (Decision List CLassifier model, Optuna study)
    """
    
    study = optuna.create_study(
        direction="maximize",
        study_name=study_name,
        sampler=optuna.samplers.TPESampler(seed=seed)
    )
    
    objective = DecisionListObjective(
        train_X,
        train_y,
        scorer,
        seed=seed,
        cv_splits=cv_splits,
        n_jobs=n_jobs, 
        random_state=seed,
        feature_names=feature_names,
        feature_types=feature_types,
        max_features=max_features,
        precision_min=precision_min,
        recall_min=recall_min,
    )
    
    study.optimize(
        objective,
        n_trials=n_trials,
        n_jobs=n_jobs,
        callbacks=[objective.best_model_callback],
        gc_after_trial=True
    )
    
    return (
        study.user_attrs["best_model"],
        study    
    )

def train_decision_list_based_on_config(train_X: pd.DataFrame, 
                                        train_y: pd.Series, 
                                        test_X: Optional[pd.DataFrame], 
                                        task_config: TrainingTaskConfig,
                                        cv_splits: int
                                        ) -> Tuple[DecisionListClassifier, Optional[pd.DataFrame]]:
    
    print("Training: Decision Rules List: Starting training.")
    if is_multiclass(train_y):
        print("Training: Decision Rule List: Multiclass classification is not supported.")
        return None, None
    else:
        metric = "f1"
    model, _ = train_decision_list_optuna(train_X.values,
                                          train_y.values,
                                          metric, 
                                          cv_splits=cv_splits, 
                                          feature_names=[*train_X.columns],
                                          feature_types=get_feature_types(train_X)
                                          )
    if task_config.output_model_path:
        print("Training: Decision Rules List: Saving model.")
        joblib.dump(model, task_config.output_model_path)

    test_pred = None
    if test_X is not None:
        print("Training: Decision Rules List: Predicting test labels.")
        test_pred = model.predict(test_X)
        if task_config.output_prediction_path:
            print("Training: Decision Rules List: Saving predicted test labels.")
            pd.Series(test_pred).to_csv(task_config.output_prediction_path)
    
    return model, test_pred
