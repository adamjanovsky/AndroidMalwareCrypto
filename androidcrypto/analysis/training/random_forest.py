"""
File contains functions that can be used to train Random Forest.

Author: Dominik Macko
"""

from functools import partial
from android_malware_labeling.training.utils import is_multiclass
from android_malware_labeling.training.config import TrainingTaskConfig
from typing import Dict, Any, Union, Callable, Tuple, List, Optional

import numpy as np
import pandas as pd
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import make_scorer, get_scorer
import optuna

from .generic import train_model, train_randomizedsearchcv_model, train_gridsearchcv_model

def random_forest_best_params_surroundings(best_params: Dict[str, Any]) -> Dict[str, Any]:
    """Get best parameters surroundings for random forest."""
    
    #min_samples_split = best_params["min_samples_split"]
    min_samples_leaf = best_params["min_samples_leaf"]
    max_depth = best_params["max_depth"]
    best_params["max_depth"] = [max_depth - 1, max_depth, max_depth + 1]
    #best_params["min_samples_split"] = [min_samples_split - 1, min_samples_split, min_samples_split + 1]
    best_params["min_samples_leaf"] = [min_samples_leaf - 1, min_samples_leaf, min_samples_leaf + 1]
    return best_params

def train_random_forest(train_X: np.array,
                        train_y: np.array,
                        scoring: Union[str, Callable[[Any, np.array, np.array], int]]="f1_macro",
                        n_jobs: int=8,
                        verbose: int=3,
                        seed: int=42,
                        cv_splits: int=5
                       ) -> Tuple[RandomForestClassifier, pd.DataFrame]:
    """Trains random forest classifier by searching for optimal alpha smoothing term.
    
    train_X - training set features
    train_y - training set targets
    scoring - scikit scoring function to use
    n_jobs - threads to use
    seed - seed to use
    verbose - scikit verbose level
    
    returns (Random Forest, history dataframe)
    """
    
    grid = {
        #"min_samples_split": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21],
        "min_samples_leaf": [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],
        "max_depth": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25],
    }
    return train_model(
        RandomForestClassifier(n_jobs=n_jobs, random_state=seed,
                               max_features="sqrt", class_weight="balanced",
                               n_estimators=100),
        train_randomizedsearchcv_model,
        train_gridsearchcv_model,
        grid,
        random_forest_best_params_surroundings,
        train_X,
        train_y,
        scoring=scoring,
        n_jobs=n_jobs,
        verbose=verbose,
        seed=seed,
        cv_splits=cv_splits
    )

class RandomForestObjective:
    """Random Forest Objective used for Optuna library to optimize"""
    
    def __init__(
        self,
        train_X: Union[pd.DataFrame, np.array],
        train_y: Union[pd.Series, np.array],
        scorer: Union[Callable[[Union[np.array, pd.Series], Union[np.array, pd.Series]], float], str],
        n_jobs: int=8,
        seed: int=42,
        class_weight: str="balanced",
        n_estimators: int=200,
        cv_splits: int=5
    ):
        """Initializes the objective
        
        train_X - training set features
        train_y - training set targets
        scorer - callable used to score performance (maximize)
        n_jobs - threads to use
        seed - random seed to use
        class_weight - class weight passed to RandomFOrestClassifier init
        n_estimators - trees to use
        """

        self.train_X = train_X
        self.train_y = train_y
        self.scorer = get_scorer(scorer) if isinstance(scorer, str) else make_scorer(scorer)
        self.n_jobs = n_jobs
        self.seed = seed
        self.class_weight = class_weight
        self.n_estimators = n_estimators
        self.cv = StratifiedKFold(n_splits=cv_splits, random_state=seed, shuffle=True)
        
    def best_model_callback(self,
                            study: optuna.study.Study,
                            trial: optuna.trial.Trial
                           ) -> None:
        """Callback that can be used to store the best model in the study."""
        
        if study.best_trial.number == trial.number:
            study.set_user_attr(key="best_model", value=trial.user_attrs["model"])
    
    def __call__(self, trial: optuna.trial.Trial) -> float:
        """Calls the objective to optimize it.
        
        trial - Optuna trial
        
        returns the scorer score on validation set
        """
        
        #min_samples_split = trial.suggest_int("min_samples_split", 2, 40)
        min_samples_leaf = trial.suggest_int("min_samples_leaf", 1, 40)
        max_depth = trial.suggest_int("max_depth", 1, 40)
        rf = RandomForestClassifier(
            n_estimators=self.n_estimators,
            #min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=self.seed,
            n_jobs=self.n_jobs,
            class_weight=self.class_weight,
            max_depth=max_depth
        )

        
        metric = np.mean(cross_val_score(rf, self.train_X, self.train_y, scoring=self.scorer, cv=self.cv, n_jobs=self.n_jobs))
        rf.fit(self.train_X, self.train_y)
        trial.set_user_attr(key="model", value=rf)
        return metric

def train_random_forest_optuna(train_X: Union[pd.DataFrame, np.array],
                               train_y: Union[pd.Series, np.array],
                               scorer: Union[Callable[[Union[np.array, pd.Series], Union[np.array, pd.Series]], float], str],
                               study_name: str="random_forest",
                               n_jobs: int=8,
                               seed: int=42,
                               n_trials: int=100,
                               cv_splits: int=5
                              ) -> Tuple[RandomForestClassifier, optuna.study.Study]:
    """Trains Random Forest using Optuna.
    
    train_X - training set features
    train_y - training set targets
    scorer - callable that is used to score the performance
    study_name - Optuna study name
    n_jobs - threads to use
    seed - random seed to use
    n_trials - maximum trials
    
    returns (Random Forest model, Optuna study)
    """
    
    study = optuna.create_study(
        direction="maximize",
        study_name=study_name,
        sampler=optuna.samplers.TPESampler(seed=seed)
    )
    
    objective = RandomForestObjective(
        train_X,
        train_y,
        scorer,
        seed=seed,
        class_weight="balanced",
        cv_splits=cv_splits
    )
    
    study.optimize(
        objective,
        n_trials=n_trials,
        n_jobs=n_jobs,
        callbacks=[objective.best_model_callback],
        gc_after_trial=True
    )
    
    return (
        study.user_attrs["best_model"],
        study    
    )

def train_random_forest_based_on_config(train_X: pd.DataFrame, 
                                        train_y: pd.Series, 
                                        test_X: Optional[pd.DataFrame], 
                                        task_config: TrainingTaskConfig,
                                        cv_splits: int
                                        ) -> Tuple[RandomForestClassifier, Optional[pd.DataFrame]]:

    print(type(get_scorer("f1_macro")))
    print(type(make_scorer("f1_macro")))
    print("Training: Random Forest: Starting training.")
    metric = "f1_macro" if is_multiclass(train_y) else "f1"
    model, _ = train_random_forest_optuna(train_X, train_y, metric, cv_splits=cv_splits)
    if task_config.output_model_path:
        print("Training: Random Forest: Saving model.")
        joblib.dump(model, task_config.output_model_path)

    test_pred = None
    if test_X is not None:
        print("Training: Random Forest: Predicting test labels.")
        test_pred = model.predict(test_X)
        if task_config.output_prediction_path:
            print("Training: Random Forest: Saving predicted test labels.")
            pd.Series(test_pred).to_csv(task_config.output_prediction_path)
    
    return model, test_pred


