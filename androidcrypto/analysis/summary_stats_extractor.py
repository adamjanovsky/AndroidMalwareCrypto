import os
from typing import Dict, Union, List, Any

from dataclasses import dataclass, field, InitVar
import pandas as pd
import pathlib
import yaml

@dataclass
class SummaryStats:

    label_types: pd.DataFrame
    label_families: pd.DataFrame
    crypto_api_imports_summary_stats: pd.DataFrame
    crypto_api_imports_usage: pd.DataFrame
    native_crypto_libs_usage: pd.DataFrame
    third_party_crypto_libs_usage: pd.DataFrame
    third_party_packages_usage: pd.DataFrame
    crypto_api_records_overall_usage: pd.DataFrame
    crypto_api_records_hashing_usage: pd.DataFrame
    crypto_api_records_digital_signature_usage: pd.DataFrame
    crypto_api_records_encryption_usage: pd.DataFrame
    crypto_api_records_key_agreement_usage: pd.DataFrame
    crypto_api_records_key_pair_generator_usage: pd.DataFrame
    crypto_api_records_mac_usage: pd.DataFrame
    crypto_api_records_secure_random_usage: pd.DataFrame

class SummaryStatsExtractor:

    def __init__(self, 
                 clean_df: pd.DataFrame, 
                 #config: pathlib.Path, 
                 api_definition: pathlib.Path,
                 ) -> "SummaryStatsExtractor":

        self._clean_df = clean_df
        self._get_records_dataframe()
        self._clean_df.drop(columns=["crypto_api_records"], inplace=True)
        #with open(config, 'r') as yaml_handle:
        #    self._config = yaml.load(yaml_handle, Loader=yaml.FullLoader)
        with open(api_definition, 'r') as yaml_handle:
            self._api_definition = self._parse_api_definition(yaml.load(yaml_handle, Loader=yaml.FullLoader))

    @staticmethod
    def _parse_api_definition(yaml_dict: Dict[str, Any]) -> Dict[str, Dict[str, List[str]]]:
        
        tasks = {}
        for task_name, task_data in yaml_dict.items():
            tasks[task_name] = {}
            values = task_data["values"]
            if isinstance(values, dict):
                tasks[task_name] = values
            elif isinstance(values, list):
                tasks[task_name] = {v: [v] for v in values}
            else:
                print("Unknown values type in api definition.")
            if "obfuscated" in task_data:
                tasks[task_name]["obfuscated"] = task_data["obfuscated"]
        return tasks

    def _get_records_dataframe(self):
        lst = []
        for row in self._clean_df.itertuples():
            if isinstance(row.crypto_api_records, dict):
                for key, records in row.crypto_api_records.items():
                    lst.extend([(row.Index, str(row.metadata_dex_year), "benign" if row.benign else "malicious", key, r[0], r[1], r[2]) for r in records])
        self._records_df = pd.DataFrame(lst, columns=["sha256", "metadata_dex_year", "maliciousness", "class_name", "trigger", "line", "line_number"])
        self._fix_broken_triggers() 

    def _fix_broken_triggers(self):
        def map_sha(x):
            if x == 'MessageDigest.getInstance("SHA1':
                return 'MessageDigest.getInstance("SHA-1'
            elif x == 'MessageDigest.getInstance("SHA256':
                return 'MessageDigest.getInstance("SHA-256'
            if x == 'MessageDigest.getInstance("SHA512':
                return 'MessageDigest.getInstance("SHA-512'
            else:
                return x

        self._records_df.trigger = self._records_df.trigger.map(map_sha)

    @classmethod
    def save(cls, stats: SummaryStats, output_dir: pathlib.Path) -> None:
        pass

    @classmethod
    def save_as_csv(cls, stats: SummaryStats, output_dir: pathlib.Path) -> None:
        
        for k, df in stats.__dict__.items():
            fpath = os.path.join(output_dir, f"{k}.csv")
            df.to_csv(fpath)


    @classmethod
    def load(cls, input_dir: pathlib.Path) -> SummaryStats:
        pass

    @classmethod
    def load_as_csv(cls, input_dir: pathlib.Path) -> SummaryStats:

        result = {}
        for k in SummaryStats.__dict__["__dataclass_fields__"].keys():
            fpath = os.path.join(input_dir, f"{k}.csv")
            result[k] = pd.read_csv(fpath)
        return SummaryStats(**result)

    def extract_all(self) -> SummaryStats:
        
        return SummaryStats(
            label_types=self.extract_label_types(),
            label_families=self.extract_label_families(),
            crypto_api_imports_summary_stats=self.extract_crypto_api_imports_summary_stats(),
            crypto_api_imports_usage=self.extract_crypto_api_imports_usage(),
            native_crypto_libs_usage=self.extract_native_crypto_libs_usage(),
            third_party_crypto_libs_usage=self.extract_third_party_crypto_libs_usage(),
            third_party_packages_usage=self.extract_third_party_packages_usage(),
            crypto_api_records_overall_usage=self.extract_crypto_api_records_overall_usage(),
            crypto_api_records_hashing_usage=self.extract_crypto_api_records_hashing_usage(),
            crypto_api_records_digital_signature_usage=self.extract_crypto_api_records_digital_signature_usage(),
            crypto_api_records_encryption_usage=self.extract_crypto_api_records_encryption_usage(),
            crypto_api_records_key_agreement_usage=self.extract_crypto_api_records_key_agreement_usage(),
            crypto_api_records_key_pair_generator_usage=self.extract_crypto_api_records_key_pair_generator_usage(),
            crypto_api_records_mac_usage=self.extract_crypto_api_records_mac_usage(),
            crypto_api_records_secure_random_usage=self.extract_crypto_api_records_secure_random_usage()
        )

    def extract_label_types(self) -> pd.DataFrame:
        
        return pd.crosstab([self._clean_df["metadata_dex_year"]], self._clean_df["metadata_euphony_name"], margins=True).reset_index()

    def extract_label_families(self) -> pd.DataFrame:
        
        return pd.crosstab([self._clean_df["metadata_dex_year"]], self._clean_df["metadata_euphony_name"], margins=True).reset_index()

    @staticmethod
    def _add_totals_to_crosstab(crosstab: pd.DataFrame) -> pd.DataFrame:
        """Adds totals to crosstab of dataframe which is based on year and maliciosness."""

        # add any maliciousness for each year
        for y in set(map(lambda t: t[0], crosstab.index)):
            row = pd.Series({
                True: crosstab.loc[(y, slice(None)), :][True].sum(),
                False: crosstab.loc[(y, slice(None)), :][False].sum()
            }, name=(y, "any"))
            crosstab = crosstab.append(row)

        # add total year
        for maliciousness in set(map(lambda t: t[1], crosstab.index)):
            row = pd.Series({
                True: crosstab.loc[(slice(None), maliciousness), :][True].sum(),
                False: crosstab.loc[(slice(None), maliciousness), :][False].sum()
            }, name=("total", maliciousness))
        return crosstab.sort_index(ascending=[True, False])

    @staticmethod
    def _extract_usage(df: pd.DataFrame, column: str, normalize: Union[str, bool]=False) -> pd.DataFrame:
        tmp = df.loc[:, [column, "metadata_dex_year", "benign"]]
        tmp[f"uses_{column}"] = tmp[column].apply(lambda l: len(l) > 0)
        tmp["maliciousness"] = tmp["benign"].apply(lambda b: "benign" if b else "malicious")
        tmp["metadata_dex_year"] = tmp["metadata_dex_year"].apply(str)
        tmp.drop(columns=[column, "benign"], inplace=True)

        crosstab = pd.crosstab([tmp["metadata_dex_year"], tmp["maliciousness"]], tmp[f"uses_{column}"], normalize=normalize)
        return SummaryStatsExtractor._add_totals_to_crosstab(crosstab)

    def extract_third_party_packages_usage(self) -> pd.DataFrame:
        
        return self._extract_usage(self._clean_df, "third_party_packages").reset_index()

    # Usage of third-party cryptographic libraries
    def extract_third_party_crypto_libs_usage(self) -> pd.DataFrame:
        
        return self._extract_usage(self._clean_df, "third_party_crypto_libs").reset_index()

    def extract_native_crypto_libs_usage(self) -> pd.DataFrame:
        
        return self._extract_usage(self._clean_df, "native_imports").reset_index()

    def extract_crypto_api_imports_usage(self) -> pd.DataFrame:
        
        return self._extract_usage(self._clean_df, "crypto_imports").reset_index()

    def extract_crypto_api_imports_summary_stats(self) -> pd.DataFrame:

        tmp = self._clean_df.loc[:, ["benign", "crypto_imports"]]
        tmp["crypto_imports_count"] = tmp["crypto_imports"].apply(lambda d: sum([*d.values()]))
        tmp["maliciousness"] = tmp["benign"].apply(lambda b: "benign" if b else "malicious")
        tmp.drop(columns=["crypto_imports", "benign"], inplace=True)
        result = tmp.groupby(by=["maliciousness"]).agg({"crypto_imports_count": ["mean", "std", "median"]})

        return result.append(
            pd.Series({
                ("crypto_imports_count", "mean"): tmp["crypto_imports_count"].mean(),
                ("crypto_imports_count", "std"): tmp["crypto_imports_count"].std(),
                ("crypto_imports_count", "median"): tmp["crypto_imports_count"].median(),
            }, name="Any")
        ).reset_index()

    def _extract_crypto_api_records_usage(self, 
        category_mappings: Dict[str, List[str]] # category: [triggers]
        ) -> pd.DataFrame:

        # reverse dictionary to trigger: category
        reverse_mapping = {e: k for k, v in category_mappings.items() for e in v}
        searched_triggers = reverse_mapping.keys()

        # drop unwanted columns
        records_df = self._records_df.drop(columns=["line", "line_number"])
        # drop records that are not in searched triggers
        records_df = records_df[records_df["trigger"].isin(searched_triggers)]
        # convert triggers to categories
        records_df["category"] = records_df["trigger"].apply(lambda t: reverse_mapping[t])
        # drop triggers because they are no longer needed
        records_df.drop(columns=["trigger"], inplace=True)

        # group together sha256 and class name, drop class name
        # (class name can be the same for different apks)
        records_df["sha256+class_name"] = records_df["sha256"] + records_df["class_name"]
        records_df.drop(columns=["class_name"], inplace=True)

        # n_apks derived from unique sha256
        # n_call_sites derived from count
        # n_classes derived from unique sha256 + class_name combination
        groupped = records_df.groupby(["category", "metadata_dex_year", "maliciousness"])
        agg = groupped.agg({"sha256": ["nunique", "size"], "sha256+class_name": "nunique"})
        agg.columns = ["_".join(a) for a in agg.columns.to_flat_index()]
        agg.rename(
            columns={
                "sha256_nunique": "n_apks",
                "sha256_size": "n_call_sites",
                "sha256+class_name_nunique": "n_classes"
                }, 
            inplace=True)
        
        agg.reset_index(inplace=True)
        # add any maliciousness (sum of benign + maliciouis)
        #for category in set(map(lambda t: t[0], agg.index)):
        #    for year in set(map(lambda t: t[1], agg.index)):
        print(agg["category"].unique())
        for category in agg["category"].unique():
            for year in agg["metadata_dex_year"].unique():
                #row_dict = {}
                row_dict = {"category": category, "metadata_dex_year": year, "maliciousness": "any"}
                for column in agg.columns:
                    if column in {"category", "metadata_dex_year", "maliciousness"}:
                        continue
                    #row_dict[column] = agg.loc[pd.IndexSlice[category, year, :], :][column].sum()
                    row_dict[column] = agg[(agg["category"] == category) & (agg["metadata_dex_year"] == year)][column].sum()
                #row = pd.Series(row_dict, name=(category, year, "any"))
                row = pd.Series(row_dict)
                agg = agg.append(row, ignore_index=True)

        # add total year
        #for category in set(map(lambda t: t[0], agg.index)):
        #    for maliciousness in set(map(lambda t: t[2], agg.index)):
        for category in agg["category"].unique():
            for maliciousness in agg["maliciousness"].unique():
                #row_dict = {}
                row_dict = {"category": category, "metadata_dex_year": "total", "maliciousness": maliciousness}
                for column in agg.columns:
                    if column in {"category", "metadata_dex_year", "maliciousness"}:
                        continue
                    #row_dict[column] = agg.loc[pd.IndexSlice[category, :, maliciousness], :][column].sum()
                    row_dict[column] = agg[(agg["category"] == category) & (agg["maliciousness"] == maliciousness)][column].sum()
                #row = pd.Series(row_dict, name=(category, "total", maliciousness))
                row = pd.Series(row_dict)
                agg = agg.append(row, ignore_index=True)

        # add total for categories
        #for year in set(map(lambda t: t[1], agg.index)):
        #    for maliciousness in set(map(lambda t: t[2], agg.index)):
        for year in agg["metadata_dex_year"].unique():
            for maliciousness in agg["maliciousness"].unique():
                #row_dict = {}
                row_dict = {"category": "total", "metadata_dex_year": year, "maliciousness": maliciousness}
                for column in agg.columns:
                    if column in {"category", "metadata_dex_year", "maliciousness"}:
                        continue
                    #row_dict[column] = agg.loc[pd.IndexSlice[:, year, maliciousness], :][column].sum()
                    row_dict[column] = agg[(agg["metadata_dex_year"] == year) & (agg["maliciousness"] == maliciousness)][column].sum()
                #row = pd.Series(row_dict, name=("total", year, maliciousness))
                row = pd.Series(row_dict)
                agg = agg.append(row, ignore_index=True)

        agg.set_index(["category", "metadata_dex_year", "maliciousness"], inplace=True)
        return agg.sort_index(ascending=[True, True, False])

    def extract_crypto_api_records_overall_usage(self) -> pd.DataFrame:
        
        merged = {}
        for task_name, task_dict in self._api_definition.items():
            # flatten 
            all_task_triggers = [item for sublist in task_dict.values() for item in sublist]
            merged[task_name] = all_task_triggers

        return self._extract_crypto_api_records_usage(merged).reset_index()

    def extract_crypto_api_records_hashing_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["hash_functions"]).reset_index()

    def extract_crypto_api_records_digital_signature_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["digital_signature"]).reset_index()

    def extract_crypto_api_records_encryption_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["encryption"]).reset_index()

    def extract_crypto_api_records_key_agreement_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["KeyAgreement"]).reset_index()

    def extract_crypto_api_records_key_pair_generator_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["KeyPairGenerator"]).reset_index()

    def extract_crypto_api_records_mac_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["MAC"]).reset_index()

    def extract_crypto_api_records_secure_random_usage(self) -> pd.DataFrame:
        return self._extract_crypto_api_records_usage(self._api_definition["SecureRandom"]).reset_index()
