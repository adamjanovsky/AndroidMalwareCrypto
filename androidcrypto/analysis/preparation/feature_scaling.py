"""
File contains class used for feature scaling.

Author: Dominik Macko
"""

from androidcrypto.analysis.preparation.saving import save_to_hdf
from androidcrypto.analysis.preparation.config import FeatureScalingConfig
from typing import List, Optional, Union, Dict, Tuple

import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn_pandas import DataFrameMapper
from sklearn.preprocessing import StandardScaler

class FeatureScalerTransformer(BaseEstimator, TransformerMixin):
    """Feature scaler that uses standard scaling for numerical values excluding bools and specified columns."""
    
    def __init__(self,
                 columns: List[str]
                ):
        """
        Initializes feature scaler that uses standard scaling for given columns.
        
        columns - list of column names that are to be scaled using standard scaling
        """
        
        super().__init__()
        self._mapper: DataFrameMapper = DataFrameMapper(
            features=[([col], StandardScaler()) for col in columns],
            default=None,
            df_out=True
        )
        
    def fit(self,
            X: pd.DataFrame,
            y: Optional[Union[pd.DataFrame, pd.Series]]=None
           ) -> "FeatureScalerTransformer":
        """Fits transformer to given training data and returns self.
        
        X - dataframe to scale
        y - target labels, unused
        
        returns self
        """
        
        self._mapper.fit(X)
        return self
        
    def transform(self,
                  X: pd.DataFrame,
                  y: Optional[Union[pd.DataFrame, pd.Series]]=None
                 ) -> pd.DataFrame:
        """Transforms given dataframe by scaling it and returns it as a dataframe.
        
        X - dataframe to scale
        y - target labels, unused
        
        returns scaled X
        """
        
        return self._mapper.transform(X)

def _get_series_by_name(df: pd.DataFrame, fallback_df: Optional[pd.DataFrame], name: str) -> Optional[pd.Series]:
    """Gets series from dataframe by name, falling back to other df when not found."""

    if name in df.columns:
        return df[name]
    if fallback_df is not None and name in fallback_df.columns:
        return fallback_df[name]
    return None

def feature_scaling_based_on_config(
    dfs: Optional[Dict[str, Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]]],
    config: FeatureScalingConfig
    ) -> Dict[str, Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]]:
    """Selects features based on a config file.
    
    returns train_X, train_y, test_X, test_y
    """

    print("Feature scaling: Starting.")
    result = {}
    used_dfs = dfs
    if dfs is None:
        dfs = {}

    for task_name, task_config in config.task_configs.items():

        # load if None
        if dfs.get(task_name, None) is None:
            if not task_config.input_hdf_path:
                print(f"Feature scaling: Task {task_name}: No data from previous step and input hdf path not defined.")
                continue
            print(f"Feature scaling: Task {task_name}: Loading data.")
            used_dfs[task_name] = (pd.read_hdf(task_config.input_hdf_path, key="X_train"),
                                   pd.read_hdf(task_config.input_hdf_path, key="y_train"),
                                   pd.read_hdf(task_config.input_hdf_path, key="X_test"),
                                   pd.read_hdf(task_config.input_hdf_path, key="y_test"))

        X_train, y_train, X_test, y_test = used_dfs[task_name]
        # temporarily remove ignored columns
        ignored_train, ignored_test = None, None
        if config.columns_to_ignore:
            ignored_train, X_train = X_train[config.columns_to_ignore], X_train.drop(columns=config.columns_to_ignore, errors="ignore")
            ignored_test, X_test = X_test[config.columns_to_ignore], X_test.drop(columns=config.columns_to_ignore, errors="ignore")

        numeric_cols =  [*X_train.select_dtypes(include="number", exclude="bool").columns]
        class_normalizer_train = _get_series_by_name(X_train, ignored_train, "metadata_n_classes")
        class_normalizer_test = _get_series_by_name(X_test, ignored_test, "metadata_n_classes")
        line_normalizer_train = _get_series_by_name(X_train, ignored_train, "metadata_n_lines")
        line_normalizer_test = _get_series_by_name(X_test, ignored_test, "metadata_n_lines")

        # normalize by class count
        if config.normalize_by_class_count:
            if not class_normalizer_train or not class_normalizer_test:
                print(f"Feature scaling: Task {task_name}: Normalizing features by class count.")
                X_train[numeric_cols] = X_train[numeric_cols] / class_normalizer_train
                X_test[numeric_cols] = X_test[numeric_cols] / class_normalizer_test
            else:
                print(f"Feature scaling: Task {task_name}: Cant normalize features by class count because `metadata_n_classes` not found.")
        
        # normalize by lines of code
        if config.normalize_by_lines_of_code:
            if not line_normalizer_train or not line_normalizer_test:
                print(f"Feature scaling: Task {task_name}: Normalizing features by class count.")
                X_train[numeric_cols] = X_train[numeric_cols] / line_normalizer_train
                X_test[numeric_cols] = X_test[numeric_cols] / line_normalizer_test
            else:
                print(f"Feature scaling: Task {task_name}: Cant normalize features by line count because `metadata_n_lines` not found.")

        # scale using standard scaling
        if config.use_standard_scaling:
            print(f"Feature scaling: Task {task_name}: Scaling features with standard scaling.")
            transformer = FeatureScalerTransformer(
                numeric_cols
            )
            X_train = transformer.fit_transform(X_train, y_train)
            X_test = transformer.transform(X_test)

        # put the ignored features back
        if config.columns_to_ignore:
            X_train[config.columns_to_ignore] = ignored_train
            X_test[config.columns_to_ignore] = ignored_test
        
        # optionally save for each of the tasks
        if task_config.output_hdf_path:
            print(f"Feature scaling: Task {task_name}: Saving output.")
            save_to_hdf(task_config.output_hdf_path, X_train, y_train, X_test, y_test)

    return result
     