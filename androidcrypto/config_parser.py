from dataclasses import dataclass, field, InitVar

import yaml
import logging
from androidcrypto.dataset import Dataset, DatasetException
import androidcrypto.helpers as helpers
import androidcrypto.constants as constants
import typing
import sys
import math


class ConfigException(Exception):
    pass


def get_size(obj, seen=None):
    """Recursively finds size of objects"""
    size = sys.getsizeof(obj)
    if seen is None:
        seen = set()
    obj_id = id(obj)
    if obj_id in seen:
        return 0
    # Important mark as seen *before* entering recursion to gracefully handle
    # self-referential objects
    seen.add(obj_id)
    if isinstance(obj, dict):
        size += sum([get_size(v, seen) for v in obj.values()])
        size += sum([get_size(k, seen) for k in obj.keys()])
    elif hasattr(obj, '__dict__'):
        size += get_size(obj.__dict__, seen)
    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):
        size += sum([get_size(i, seen) for i in obj])
    return size


class ExperimentConfigParser:
    def __init__(self, path_to_config_file, neptune_token=None, androzoo_token=None):
        self.androzoo_token = androzoo_token
        self.neptune_token = neptune_token
        self.path_to_config_file = path_to_config_file
        self.task_parser_functions = {constants.TaskName.DOWNLOAD: self.TaskDownloadConfig,
                                      constants.TaskName.DECOMPILE: self.TaskDecompileConfig,
                                      constants.TaskName.THIRD_PARTY_LIBS: self.TaskThirdPartyLibsConfig,
                                      constants.TaskName.EVALUATE: self.TaskEvaluateConfig,
                                      constants.TaskName.LABEL: self.TaskLabelConfig}

    def __repr__(self):
        return f'Path to config file: {self.path_to_config_file}, Androzoo token: {self.androzoo_token}, Neptune token: {self.neptune_token}'

    @dataclass(frozen=True)
    class TaskDownloadConfig:
        start_year: str = field(init=False, default=2012)
        end_year: str = field(init=False, default=2020)
        max_size: int = field(init=False, default=20000)
        csv_path: str = field(init=False)
        minimal_vt_positives: int = field(init=False, default=5)
        maximal_vt_positives: int = field(init=False, default=math.inf)
        n_samples: int = field(init=False, default=1)
        api_token: str = field(init=False, default=None)
        delete_apks: bool = field(init=False, default=False)
        strategy: str = field(init=False, default='uniform')

        stream: InitVar[dict]

        # TODO: Input sanitation should happen here
        def __post_init__(self, stream: dict):
            for key, val in stream.items():
                super().__setattr__(str(key), val)

    @dataclass(frozen=True)
    class TaskDecompileConfig:
        delete_dxs: bool = field(init=False, default=False)
        jadx_path: str = field(init=False, default='jadx')
        stream: InitVar[dict]

        def __post_init__(self, stream: dict):
            for key, val in stream.items():
                super().__setattr__(str(key), val)

    @dataclass(frozen=True)
    class TaskThirdPartyLibsConfig:
        literadar_path: str = field(init=False, default=None)
        crypto_libs: list = field(init=False, default=None)
        stream: InitVar[dict]

        def __post_init__(self, stream: dict):
            for key, val in stream.items():
                super().__setattr__(str(key), val)

    @dataclass(frozen=True)
    class TaskEvaluateConfig:
        categories: dict = field(init=False, default=None)
        imports: list = field(init=False, default=None)
        keywords: list = field(init=False)
        native_imports: list = field(init=False)
        stream: InitVar[dict]

        def __post_init__(self, stream: dict):
            for key, val in stream.items():
                super().__setattr__(str(key), val)
            super().__setattr__('keywords', helpers.flatten_list(self.categories.values()))

    @dataclass(frozen=True)
    class TaskLabelConfig:
        euphony_names_path: str = field(init=False, default=None)
        euphony_types_path: str = field(init=False, default=None)
        stream: InitVar[dict]

        def __post_init__(self, stream: dict):
            for key, val in stream.items():
                super().__setattr__(str(key), val)

    @dataclass(frozen=True)
    class ExperimentConfig:
        experiment_name: str
        neptune_api_token: str
        neptune_project_name: str
        is_being_logged: bool
        dset: Dataset
        n_threads: int
        timeout: int
        tasks: dict
        delete_corrupted: bool
        config_path: bool

    @staticmethod
    def parse_tasks(tasks_field):
        if isinstance(tasks_field, str):
            if tasks_field != constants.ALL_TASKS:
                raise ConfigException('Tasks must either be a list or \'all\' word.')
            else:
                return {x: None for x in constants.TaskName}
        else:
            task_codes = [str(x) for x in constants.TaskName]
            if any([x not in task_codes for x in tasks_field]):
                raise ConfigException(f'Uknown tasks: {[x for x in tasks_field if x not in task_codes]}')
            return {key: None for key in constants.TaskName if str(key) in tasks_field}

    def parse_config_file(self):
        try:
            with open(self.path_to_config_file, 'r') as stream:
                config_stream = yaml.load(stream, Loader=yaml.FullLoader)
        except OSError:
            raise ConfigException('No config file found in config filepath.')

        tasks = self.parse_tasks(self.get_type(config_stream, 'tasks', typing.Any))
        is_being_logged = (self.neptune_token is not None and self.get_type(config_stream, 'is_being_logged', bool) is True)
        n_threads = self.get_type(config_stream, 'n_threads', int)
        neptune_project_name = self.get_type(config_stream, 'neptune_project_name', str) if is_being_logged else None
        experiment_name = self.get_type(config_stream, 'experiment_name', str) if is_being_logged else None
        dataset_path = self.get_type(config_stream, 'dataset_path', str)
        delete_corrupted = self.get_type(config_stream, 'delete_corrupted', bool)

        try:
            dset = Dataset(dataset_path)
        except DatasetException:
            logging.critical("Failed to initialize dataset. Exiting.")
            raise ConfigException(f'Failed to initialize dataset from: {dataset_path} path.')

        timeout = self.get_type(config_stream, 'timeout', int)

        if constants.TaskName.DOWNLOAD in tasks.keys():
            config_stream[str(constants.TaskName.DOWNLOAD)]['api_token'] = self.androzoo_token

        for t in tasks.keys():
            tasks[t] = self.task_parser_functions[t](config_stream[str(t)])

        return self.ExperimentConfig(experiment_name, self.neptune_token, neptune_project_name,
                                     is_being_logged, dset, n_threads, timeout, tasks, delete_corrupted, self.path_to_config_file)

    @staticmethod
    def get_type(stream, name, type_to_decode):
        if name not in stream:
            raise ConfigException(f'The value {name} is not set in the config file.')

        value = stream[name]

        if type_to_decode == typing.Any or type(value) == type_to_decode:
            return value
        else:
            raise ConfigException(f'The value {name} should be {type_to_decode}, but is {type(value)}')
